[{"id":0,"href":"/about-me/","title":"About me","section":"","content":" About me # Cuong Nguyen Duc\nSRE | DevOps Engineer\nHCMC, Vietnam\nLinkedIn: https://www.linkedin.com/in/ndcuong\nSRE | DevOps Engineer with 5+ years working in a variety of environment, from mixed physical, virtual environment moving to cloud.\nEnable CI/CD pipeline using Devops toolchain to speed up software development cycle Ensure infrastructure/application performance and stability by apply proactively monitoring and alert. Strong team/cross-team work. Good planning, documenting and troubleshooting skill. Devops mindset, willing to fill the gap between development and operation. Ability to quickly learn new skills to meet the need. Github : https://github.com/cuong-ts Certificates # AWS Certified Solutions Architect (2020) HashiCorp Certified: Terraform Associate (2021) Google Cloud Certified: Associate Cloud Engineer (2021) Advanced English Writing and Grammar (2018) # "},{"id":1,"href":"/posts/creating-a-new-theme/","title":"Creating a New Theme","section":"Blogs","content":" Introduction # This tutorial will show you how to create a simple theme in Hugo. I assume that you are familiar with HTML, the bash command line, and that you are comfortable using Markdown to format content. I\u0026rsquo;ll explain how Hugo uses templates and how you can organize your templates to create a theme. I won\u0026rsquo;t cover using CSS to style your theme.\nWe\u0026rsquo;ll start with creating a new site with a very basic template. Then we\u0026rsquo;ll add in a few pages and posts. With small variations on that, you will be able to create many different types of web sites.\nIn this tutorial, commands that you enter will start with the \u0026ldquo;$\u0026rdquo; prompt. The output will follow. Lines that start with \u0026ldquo;#\u0026rdquo; are comments that I\u0026rsquo;ve added to explain a point. When I show updates to a file, the \u0026ldquo;:wq\u0026rdquo; on the last line means to save the file.\nHere\u0026rsquo;s an example:\n## this is a comment $ echo this is a command this is a command ## edit the file $ vi foo.md +++ date = \u0026#34;2014-09-28\u0026#34; title = \u0026#34;creating a new theme\u0026#34; +++ bah and humbug :wq ## show it $ cat foo.md +++ date = \u0026#34;2014-09-28\u0026#34; title = \u0026#34;creating a new theme\u0026#34; +++ bah and humbug $ Some Definitions # There are a few concepts that you need to understand before creating a theme.\nSkins # Skins are the files responsible for the look and feel of your site. It’s the CSS that controls colors and fonts, it’s the Javascript that determines actions and reactions. It’s also the rules that Hugo uses to transform your content into the HTML that the site will serve to visitors.\nYou have two ways to create a skin. The simplest way is to create it in the layouts/ directory. If you do, then you don’t have to worry about configuring Hugo to recognize it. The first place that Hugo will look for rules and files is in the layouts/ directory so it will always find the skin.\nYour second choice is to create it in a sub-directory of the themes/ directory. If you do, then you must always tell Hugo where to search for the skin. It’s extra work, though, so why bother with it?\nThe difference between creating a skin in layouts/ and creating it in themes/ is very subtle. A skin in layouts/ can’t be customized without updating the templates and static files that it is built from. A skin created in themes/, on the other hand, can be and that makes it easier for other people to use it.\nThe rest of this tutorial will call a skin created in the themes/ directory a theme.\nNote that you can use this tutorial to create a skin in the layouts/ directory if you wish to. The main difference will be that you won’t need to update the site’s configuration file to use a theme.\nThe Home Page # The home page, or landing page, is the first page that many visitors to a site see. It is the index.html file in the root directory of the web site. Since Hugo writes files to the public/ directory, our home page is public/index.html.\nSite Configuration File # When Hugo runs, it looks for a configuration file that contains settings that override default values for the entire site. The file can use TOML, YAML, or JSON. I prefer to use TOML for my configuration files. If you prefer to use JSON or YAML, you’ll need to translate my examples. You’ll also need to change the name of the file since Hugo uses the extension to determine how to process it.\nHugo translates Markdown files into HTML. By default, Hugo expects to find Markdown files in your content/ directory and template files in your themes/ directory. It will create HTML files in your public/ directory. You can change this by specifying alternate locations in the configuration file.\nContent # Content is stored in text files that contain two sections. The first section is the “front matter,” which is the meta-information on the content. The second section contains Markdown that will be converted to HTML.\nFront Matter # The front matter is information about the content. Like the configuration file, it can be written in TOML, YAML, or JSON. Unlike the configuration file, Hugo doesn’t use the file’s extension to know the format. It looks for markers to signal the type. TOML is surrounded by “+++”, YAML by “---”, and JSON is enclosed in curly braces. I prefer to use TOML, so you’ll need to translate my examples if you prefer YAML or JSON.\nThe information in the front matter is passed into the template before the content is rendered into HTML.\nMarkdown # Content is written in Markdown which makes it easier to create the content. Hugo runs the content through a Markdown engine to create the HTML which will be written to the output file.\nTemplate Files # Hugo uses template files to render content into HTML. Template files are a bridge between the content and presentation. Rules in the template define what content is published, where it\u0026rsquo;s published to, and how it will rendered to the HTML file. The template guides the presentation by specifying the style to use.\nThere are three types of templates: single, list, and partial. Each type takes a bit of content as input and transforms it based on the commands in the template.\nHugo uses its knowledge of the content to find the template file used to render the content. If it can’t find a template that is an exact match for the content, it will shift up a level and search from there. It will continue to do so until it finds a matching template or runs out of templates to try. If it can’t find a template, it will use the default template for the site.\nPlease note that you can use the front matter to influence Hugo’s choice of templates.\nSingle Template # A single template is used to render a single piece of content. For example, an article or post would be a single piece of content and use a single template.\nList Template # A list template renders a group of related content. That could be a summary of recent postings or all articles in a category. List templates can contain multiple groups.\nThe homepage template is a special type of list template. Hugo assumes that the home page of your site will act as the portal for the rest of the content in the site.\nPartial Template # A partial template is a template that can be included in other templates. Partial templates must be called using the “partial” template command. They are very handy for rolling up common behavior. For example, your site may have a banner that all pages use. Instead of copying the text of the banner into every single and list template, you could create a partial with the banner in it. That way if you decide to change the banner, you only have to change the partial template.\nCreate a New Site # Let\u0026rsquo;s use Hugo to create a new web site. I\u0026rsquo;m a Mac user, so I\u0026rsquo;ll create mine in my home directory, in the Sites folder. If you\u0026rsquo;re using Linux, you might have to create the folder first.\nThe \u0026ldquo;new site\u0026rdquo; command will create a skeleton of a site. It will give you the basic directory structure and a useable configuration file.\n$ hugo new site ~/Sites/zafta $ cd ~/Sites/zafta $ ls -l total 8 drwxr-xr-x 7 quoha staff 238 Sep 29 16:49 . drwxr-xr-x 3 quoha staff 102 Sep 29 16:49 .. drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $ Take a look in the content/ directory to confirm that it is empty.\nThe other directories (archetypes/, layouts/, and static/) are used when customizing a theme. That\u0026rsquo;s a topic for a different tutorial, so please ignore them for now.\nGenerate the HTML For the New Site # Running the hugo command with no options will read all the available content and generate the HTML files. It will also copy all static files (that\u0026rsquo;s everything that\u0026rsquo;s not content). Since we have an empty site, it won\u0026rsquo;t do much, but it will do it very quickly.\n$ hugo --verbose INFO: 2014/09/29 Using config file: config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ The \u0026ldquo;--verbose\u0026rdquo; flag gives extra information that will be helpful when we build the template. Every line of the output that starts with \u0026ldquo;INFO:\u0026rdquo; or \u0026ldquo;WARN:\u0026rdquo; is present because we used that flag. The lines that start with \u0026ldquo;WARN:\u0026rdquo; are warning messages. We\u0026rsquo;ll go over them later.\nWe can verify that the command worked by looking at the directory again.\n$ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $ See that new public/ directory? Hugo placed all generated content there. When you\u0026rsquo;re ready to publish your web site, that\u0026rsquo;s the place to start. For now, though, let\u0026rsquo;s just confirm that we have what we\u0026rsquo;d expect from a site with no content.\n$ ls -l public total 16 -rw-r--r-- 1 quoha staff 416 Sep 29 17:02 index.xml -rw-r--r-- 1 quoha staff 262 Sep 29 17:02 sitemap.xml $ Hugo created two XML files, which is standard, but there are no HTML files.\nTest the New Site # Verify that you can run the built-in web server. It will dramatically shorten your development cycle if you do. Start it by running the \u0026ldquo;server\u0026rdquo; command. If it is successful, you will see output similar to the following:\n$ hugo server --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop Connect to the listed URL (it\u0026rsquo;s on the line that starts with \u0026ldquo;Web Server\u0026rdquo;). If everything is working correctly, you should get a page that shows the following:\nindex.xml sitemap.xml That\u0026rsquo;s a listing of your public/ directory. Hugo didn\u0026rsquo;t create a home page because our site has no content. When there\u0026rsquo;s no index.html file in a directory, the server lists the files in the directory, which is what you should see in your browser.\nLet’s go back and look at those warnings again.\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] That second warning is easier to explain. We haven’t created a template to be used to generate “page not found errors.” The 404 message is a topic for a separate tutorial.\nNow for the first warning. It is for the home page. You can tell because the first layout that it looked for was “index.html.” That’s only used by the home page.\nI like that the verbose flag causes Hugo to list the files that it\u0026rsquo;s searching for. For the home page, they are index.html, _default/list.html, and _default/single.html. There are some rules that we\u0026rsquo;ll cover later that explain the names and paths. For now, just remember that Hugo couldn\u0026rsquo;t find a template for the home page and it told you so.\nAt this point, you\u0026rsquo;ve got a working installation and site that we can build upon. All that’s left is to add some content and a theme to display it.\nCreate a New Theme # Hugo doesn\u0026rsquo;t ship with a default theme. There are a few available (I counted a dozen when I first installed Hugo) and Hugo comes with a command to create new themes.\nWe\u0026rsquo;re going to create a new theme called \u0026ldquo;zafta.\u0026rdquo; Since the goal of this tutorial is to show you how to fill out the files to pull in your content, the theme will not contain any CSS. In other words, ugly but functional.\nAll themes have opinions on content and layout. For example, Zafta uses \u0026ldquo;post\u0026rdquo; over \u0026ldquo;blog\u0026rdquo;. Strong opinions make for simpler templates but differing opinions make it tougher to use themes. When you build a theme, consider using the terms that other themes do.\nCreate a Skeleton # Use the hugo \u0026ldquo;new\u0026rdquo; command to create the skeleton of a theme. This creates the directory structure and places empty files for you to fill out.\n$ hugo new theme zafta $ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes $ find themes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 1081 Sep 29 17:31 themes/zafta/LICENSE.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html -rw-r--r-- 1 quoha staff 93 Sep 29 17:31 themes/zafta/theme.toml $ The skeleton includes templates (the files ending in .html), license file, a description of your theme (the theme.toml file), and an empty archetype.\nPlease take a minute to fill out the theme.toml and LICENSE.md files. They\u0026rsquo;re optional, but if you\u0026rsquo;re going to be distributing your theme, it tells the world who to praise (or blame). It\u0026rsquo;s also nice to declare the license so that people will know how they can use the theme.\n$ vi themes/zafta/theme.toml author = \u0026#34;michael d henderson\u0026#34; description = \u0026#34;a minimal working template\u0026#34; license = \u0026#34;MIT\u0026#34; name = \u0026#34;zafta\u0026#34; source_repo = \u0026#34;\u0026#34; tags = [\u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34;] :wq ## also edit themes/zafta/LICENSE.md and change ## the bit that says \u0026#34;YOUR_NAME_HERE\u0026#34; Note that the the skeleton\u0026rsquo;s template files are empty. Don\u0026rsquo;t worry, we\u0026rsquo;ll be changing that shortly.\n$ find themes/zafta -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html $ Update the Configuration File to Use the Theme # Now that we\u0026rsquo;ve got a theme to work with, it\u0026rsquo;s a good idea to add the theme name to the configuration file. This is optional, because you can always add \u0026ldquo;-t zafta\u0026rdquo; on all your commands. I like to put it the configuration file because I like shorter command lines. If you don\u0026rsquo;t put it in the configuration file or specify it on the command line, you won\u0026rsquo;t use the template that you\u0026rsquo;re expecting to.\nEdit the file to add the theme, add a title for the site, and specify that all of our content will use the TOML format.\n$ vi config.toml theme = \u0026#34;zafta\u0026#34; baseurl = \u0026#34;\u0026#34; languageCode = \u0026#34;en-us\u0026#34; title = \u0026#34;zafta - totally refreshing\u0026#34; MetaDataFormat = \u0026#34;toml\u0026#34; :wq $ Generate the Site # Now that we have an empty theme, let\u0026rsquo;s generate the site again.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ Did you notice that the output is different? The warning message for the home page has disappeared and we have an additional information line saying that Hugo is syncing from the theme\u0026rsquo;s directory.\nLet\u0026rsquo;s check the public/ directory to see what Hugo\u0026rsquo;s created.\n$ ls -l public total 16 drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 css -rw-r--r-- 1 quoha staff 0 Sep 29 17:56 index.html -rw-r--r-- 1 quoha staff 407 Sep 29 17:56 index.xml drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 js -rw-r--r-- 1 quoha staff 243 Sep 29 17:56 sitemap.xml $ Notice four things:\nHugo created a home page. This is the file public/index.html. Hugo created a css/ directory. Hugo created a js/ directory. Hugo claimed that it created 0 pages. It created a file and copied over static files, but didn\u0026rsquo;t create any pages. That\u0026rsquo;s because it considers a \u0026ldquo;page\u0026rdquo; to be a file created directly from a content file. It doesn\u0026rsquo;t count things like the index.html files that it creates automatically. The Home Page # Hugo supports many different types of templates. The home page is special because it gets its own type of template and its own template file. The file, layouts/index.html, is used to generate the HTML for the home page. The Hugo documentation says that this is the only required template, but that depends. Hugo\u0026rsquo;s warning message shows that it looks for three different templates:\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] If it can\u0026rsquo;t find any of these, it completely skips creating the home page. We noticed that when we built the site without having a theme installed.\nWhen Hugo created our theme, it created an empty home page template. Now, when we build the site, Hugo finds the template and uses it to generate the HTML for the home page. Since the template file is empty, the HTML file is empty, too. If the template had any rules in it, then Hugo would have used them to generate the home page.\n$ find . -name index.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 20:21 ./public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 ./themes/zafta/layouts/index.html $ The Magic of Static # Hugo does two things when generating the site. It uses templates to transform content into HTML and it copies static files into the site. Unlike content, static files are not transformed. They are copied exactly as they are.\nHugo assumes that your site will use both CSS and JavaScript, so it creates directories in your theme to hold them. Remember opinions? Well, Hugo\u0026rsquo;s opinion is that you\u0026rsquo;ll store your CSS in a directory named css/ and your JavaScript in a directory named js/. If you don\u0026rsquo;t like that, you can change the directory names in your theme directory or even delete them completely. Hugo\u0026rsquo;s nice enough to offer its opinion, then behave nicely if you disagree.\n$ find themes/zafta -type d | xargs ls -ld drwxr-xr-x 7 quoha staff 238 Sep 29 17:38 themes/zafta drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes/zafta/archetypes drwxr-xr-x 5 quoha staff 170 Sep 29 17:31 themes/zafta/layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/_default drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/partials drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/static drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/css drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/js $ The Theme Development Cycle # When you\u0026rsquo;re working on a theme, you will make changes in the theme\u0026rsquo;s directory, rebuild the site, and check your changes in the browser. Hugo makes this very easy:\nPurge the public/ directory. Run the built in web server in watch mode. Open your site in a browser. Update the theme. Glance at your browser window to see changes. Return to step 4. I’ll throw in one more opinion: never work on a theme on a live site. Always work on a copy of your site. Make changes to your theme, test them, then copy them up to your site. For added safety, use a tool like Git to keep a revision history of your content and your theme. Believe me when I say that it is too easy to lose both your mind and your changes.\nCheck the main Hugo site for information on using Git with Hugo.\nPurge the public/ Directory # When generating the site, Hugo will create new files and update existing ones in the public/ directory. It will not delete files that are no longer used. For example, files that were created in the wrong directory or with the wrong title will remain. If you leave them, you might get confused by them later. I recommend cleaning out your site prior to generating it.\nNote: If you\u0026rsquo;re building on an SSD, you should ignore this. Churning on a SSD can be costly.\nHugo\u0026rsquo;s Watch Option # Hugo\u0026rsquo;s \u0026ldquo;--watch\u0026rdquo; option will monitor the content/ and your theme directories for changes and rebuild the site automatically.\nLive Reload # Hugo\u0026rsquo;s built in web server supports live reload. As pages are saved on the server, the browser is told to refresh the page. Usually, this happens faster than you can say, \u0026ldquo;Wow, that\u0026rsquo;s totally amazing.\u0026rdquo;\nDevelopment Commands # Use the following commands as the basis for your workflow.\n## purge old files. hugo will recreate the public directory. ## $ rm -rf public ## ## run hugo in watch mode ## $ hugo server --watch --verbose Here\u0026rsquo;s sample output showing Hugo detecting a change to the template for the home page. Once generated, the web browser automatically reloaded the page. I\u0026rsquo;ve said this before, it\u0026rsquo;s amazing.\n$ rm -rf public $ hugo server --watch --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Watching for changes in /Users/quoha/Sites/zafta/content Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop INFO: 2014/09/29 File System Event: [\u0026#34;/Users/quoha/Sites/zafta/themes/zafta/layouts/index.html\u0026#34;: MODIFY|ATTRIB] Change detected, rebuilding site WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 1 ms Update the Home Page Template # The home page is one of a few special pages that Hugo creates automatically. As mentioned earlier, it looks for one of three files in the theme\u0026rsquo;s layout/ directory:\nindex.html _default/list.html _default/single.html We could update one of the default templates, but a good design decision is to update the most specific template available. That\u0026rsquo;s not a hard and fast rule (in fact, we\u0026rsquo;ll break it a few times in this tutorial), but it is a good generalization.\nMake a Static Home Page # Right now, that page is empty because we don\u0026rsquo;t have any content and we don\u0026rsquo;t have any logic in the template. Let\u0026rsquo;s change that by adding some text to the template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Build the web site and then verify the results.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 21:26 public/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt; Live Reload # Note: If you\u0026rsquo;re running the server with the --watch option, you\u0026rsquo;ll see different content in the file:\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt;document.write(\u0026#39;\u0026lt;script src=\u0026#34;http://\u0026#39; + (location.host || \u0026#39;localhost\u0026#39;).split(\u0026#39;:\u0026#39;)[0] + \u0026#39;:1313/livereload.js?mindelay=10\u0026#34;\u0026gt;\u0026lt;/\u0026#39; + \u0026#39;script\u0026gt;\u0026#39;)\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; When you use --watch, the Live Reload script is added by Hugo. Look for live reload in the documentation to see what it does and how to disable it.\nBuild a \u0026ldquo;Dynamic\u0026rdquo; Home Page # \u0026ldquo;Dynamic home page?\u0026rdquo; Hugo\u0026rsquo;s a static web site generator, so this seems an odd thing to say. I mean let\u0026rsquo;s have the home page automatically reflect the content in the site every time Hugo builds it. We\u0026rsquo;ll use iteration in the template to do that.\nCreate New Posts # Now that we have the home page generating static content, let\u0026rsquo;s add some content to the site. We\u0026rsquo;ll display these posts as a list on the home page and on their own page, too.\nHugo has a command to generate a skeleton post, just like it does for sites and themes.\n$ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/default.md ERROR: 2014/09/29 Unable to Cast \u0026lt;nil\u0026gt; to map[string]interface{} $ That wasn\u0026rsquo;t very nice, was it?\nThe \u0026ldquo;new\u0026rdquo; command uses an archetype to create the post file. Hugo created an empty default archetype file, but that causes an error when there\u0026rsquo;s a theme. For me, the workaround was to create an archetypes file specifically for the post type.\n$ vi themes/zafta/archetypes/post.md +++ Description = \u0026#34;\u0026#34; Tags = [] Categories = [] +++ :wq $ find themes/zafta/archetypes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 21:53 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 51 Sep 29 21:54 themes/zafta/archetypes/post.md $ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/first.md /Users/quoha/Sites/zafta/content/post/first.md created $ hugo --verbose new post/second.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/second.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/second.md /Users/quoha/Sites/zafta/content/post/second.md created $ ls -l content/post total 16 -rw-r--r-- 1 quoha staff 104 Sep 29 21:54 first.md -rw-r--r-- 1 quoha staff 105 Sep 29 21:57 second.md $ cat content/post/first.md +++ Categories = [] Description = \u0026#34;\u0026#34; Tags = [] date = \u0026#34;2014-09-29T21:54:53-05:00\u0026#34; title = \u0026#34;first\u0026#34; +++ my first post $ cat content/post/second.md +++ Categories = [] Description = \u0026#34;\u0026#34; Tags = [] date = \u0026#34;2014-09-29T21:57:09-05:00\u0026#34; title = \u0026#34;second\u0026#34; +++ my second post $ Build the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;, \u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ The output says that it created 2 pages. Those are our new posts:\n$ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 22:13 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/second/index.html $ The new files are empty because because the templates used to generate the content are empty. The homepage doesn\u0026rsquo;t show the new content, either. We have to update the templates to add the posts.\nList and Single Templates # In Hugo, we have three major kinds of templates. There\u0026rsquo;s the home page template that we updated previously. It is used only by the home page. We also have \u0026ldquo;single\u0026rdquo; templates which are used to generate output for a single content file. We also have \u0026ldquo;list\u0026rdquo; templates that are used to group multiple pieces of content before generating output.\nGenerally speaking, list templates are named \u0026ldquo;list.html\u0026rdquo; and single templates are named \u0026ldquo;single.html.\u0026rdquo;\nThere are three other types of templates: partials, content views, and terms. We will not go into much detail on these.\nAdd Content to the Homepage # The home page will contain a list of posts. Let\u0026rsquo;s update its template to add the posts that we just created. The logic in the template will run every time we build the site.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Hugo uses the Go template engine. That engine scans the template files for commands which are enclosed between \u0026ldquo;{{\u0026rdquo; and \u0026ldquo;}}\u0026rdquo;. In our template, the commands are:\nrange .Title end The \u0026ldquo;range\u0026rdquo; command is an iterator. We\u0026rsquo;re going to use it to go through the first ten pages. Every HTML file that Hugo creates is treated as a page, so looping through the list of pages will look at every file that will be created.\nThe \u0026ldquo;.Title\u0026rdquo; command prints the value of the \u0026ldquo;title\u0026rdquo; variable. Hugo pulls it from the front matter in the Markdown file.\nThe \u0026ldquo;end\u0026rdquo; command signals the end of the range iterator. The engine loops back to the top of the iteration when it finds \u0026ldquo;end.\u0026rdquo; Everything between the \u0026ldquo;range\u0026rdquo; and \u0026ldquo;end\u0026rdquo; is evaluated every time the engine goes through the iteration. In this file, that would cause the title from the first ten pages to be output as heading level one.\nIt\u0026rsquo;s helpful to remember that some variables, like .Data, are created before any output files. Hugo loads every content file into the variable and then gives the template a chance to process before creating the HTML files.\nBuild the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:23 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Congratulations, the home page shows the title of the two posts. The posts themselves are still empty, but let\u0026rsquo;s take a moment to appreciate what we\u0026rsquo;ve done. Your template now generates output dynamically. Believe it or not, by inserting the range command inside of those curly braces, you\u0026rsquo;ve learned everything you need to know to build a theme. All that\u0026rsquo;s really left is understanding which template will be used to generate each content file and becoming familiar with the commands for the template engine.\nAnd, if that were entirely true, this tutorial would be much shorter. There are a few things to know that will make creating a new template much easier. Don\u0026rsquo;t worry, though, that\u0026rsquo;s all to come.\nAdd Content to the Posts # We\u0026rsquo;re working with posts, which are in the content/post/ directory. That means that their section is \u0026ldquo;post\u0026rdquo; (and if we don\u0026rsquo;t do something weird, their type is also \u0026ldquo;post\u0026rdquo;).\nHugo uses the section and type to find the template file for every piece of content. Hugo will first look for a template file that matches the section or type name. If it can\u0026rsquo;t find one, then it will look in the _default/ directory. There are some twists that we\u0026rsquo;ll cover when we get to categories and tags, but for now we can assume that Hugo will try post/single.html, then _default/single.html.\nNow that we know the search rule, let\u0026rsquo;s see what we actually have available:\n$ find themes/zafta -name single.html | xargs ls -l -rw-r--r-- 1 quoha staff 132 Sep 29 17:31 themes/zafta/layouts/_default/single.html We could create a new template, post/single.html, or change the default. Since we don\u0026rsquo;t know of any other content types, let\u0026rsquo;s start with updating the default.\nRemember, any content that we haven\u0026rsquo;t created a template for will end up using this template. That can be good or bad. Bad because I know that we\u0026rsquo;re going to be adding different types of content and we\u0026rsquo;re going to end up undoing some of the changes we\u0026rsquo;ve made. It\u0026rsquo;s good because we\u0026rsquo;ll be able to see immediate results. It\u0026rsquo;s also good to start here because we can start to build the basic layout for the site. As we add more content types, we\u0026rsquo;ll refactor this file and move logic around. Hugo makes that fairly painless, so we\u0026rsquo;ll accept the cost and proceed.\nPlease see the Hugo documentation on template rendering for all the details on determining which template to use. And, as the docs mention, if you\u0026rsquo;re building a single page application (SPA) web site, you can delete all of the other templates and work with just the default single page. That\u0026rsquo;s a refreshing amount of joy right there.\nUpdate the Template File # $ vi themes/zafta/layouts/_default/single.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:40 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:40 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:40 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:40 public/post/second/index.html $ cat public/post/first/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;first\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my first post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ cat public/post/second/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;second\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my second post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Notice that the posts now have content. You can go to localhost:1313/post/first to verify.\nLinking to Content # The posts are on the home page. Let\u0026rsquo;s add a link from there to the post. Since this is the home page, we\u0026rsquo;ll update its template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 149 Sep 29 22:44 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:44 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:44 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:44 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;/post/second/\u0026#34;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;/post/first/\u0026#34;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Create a Post Listing # We have the posts displaying on the home page and on their own page. We also have a file public/post/index.html that is empty. Let\u0026rsquo;s make it show a list of all posts (not just the first ten).\nWe need to decide which template to update. This will be a listing, so it should be a list template. Let\u0026rsquo;s take a quick look and see which list templates are available.\n$ find themes/zafta -name list.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html As with the single post, we have to decide to update _default/list.html or create post/list.html. We still don\u0026rsquo;t have multiple content types, so let\u0026rsquo;s stay consistent and update the default list template.\nCreating Top Level Pages # Let\u0026rsquo;s add an \u0026ldquo;about\u0026rdquo; page and display it at the top level (as opposed to a sub-level like we did with posts).\nThe default in Hugo is to use the directory structure of the content/ directory to guide the location of the generated html in the public/ directory. Let\u0026rsquo;s verify that by creating an \u0026ldquo;about\u0026rdquo; page at the top level:\n$ vi content/about.md +++ title = \u0026#34;about\u0026#34; description = \u0026#34;about this site\u0026#34; date = \u0026#34;2014-09-27\u0026#34; slug = \u0026#34;about time\u0026#34; +++ ## about us i\u0026#39;m speechless :wq Generate the web site and verify the results.\n$ find public -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:08 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 527 Sep 27 15:08 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:08 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:08 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:08 public/post/second-post/index.html Notice that the page wasn\u0026rsquo;t created at the top level. It was created in a sub-directory named \u0026lsquo;about-time/\u0026rsquo;. That name came from our slug. Hugo will use the slug to name the generated content. It\u0026rsquo;s a reasonable default, by the way, but we can learn a few things by fighting it for this file.\nOne other thing. Take a look at the home page.\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/theme/\u0026#34;\u0026gt;creating a new theme\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/about-time/\u0026#34;\u0026gt;about\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/second-post/\u0026#34;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/first-post/\u0026#34;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;script\u0026gt;document.write(\u0026#39;\u0026lt;script src=\u0026#34;http://\u0026#39; + (location.host || \u0026#39;localhost\u0026#39;).split(\u0026#39;:\u0026#39;)[0] + \u0026#39;:1313/livereload.js?mindelay=10\u0026#34;\u0026gt;\u0026lt;/\u0026#39; + \u0026#39;script\u0026gt;\u0026#39;)\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Notice that the \u0026ldquo;about\u0026rdquo; link is listed with the posts? That\u0026rsquo;s not desirable, so let\u0026rsquo;s change that first.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026#34;post\u0026#34;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if eq .Type \u0026#34;page\u0026#34; }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq Generate the web site and verify the results. The home page has two sections, posts and pages, and each section has the right set of headings and links in it.\nBut, that about page still renders to about-time/index.html.\n$ find public -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:33 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 645 Sep 27 15:33 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:33 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:33 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:33 public/post/second-post/index.html Knowing that hugo is using the slug to generate the file name, the simplest solution is to change the slug. Let\u0026rsquo;s do it the hard way and change the permalink in the configuration file.\n$ vi config.toml [permalinks] page = \u0026#34;/:title/\u0026#34; about = \u0026#34;/:filename/\u0026#34; Generate the web site and verify that this didn\u0026rsquo;t work. Hugo lets \u0026ldquo;slug\u0026rdquo; or \u0026ldquo;URL\u0026rdquo; override the permalinks setting in the configuration file. Go ahead and comment out the slug in content/about.md, then generate the web site to get it to be created in the right place.\nSharing Templates # If you\u0026rsquo;ve been following along, you probably noticed that posts have titles in the browser and the home page doesn\u0026rsquo;t. That\u0026rsquo;s because we didn\u0026rsquo;t put the title in the home page\u0026rsquo;s template (layouts/index.html). That\u0026rsquo;s an easy thing to do, but let\u0026rsquo;s look at a different option.\nWe can put the common bits into a shared template that\u0026rsquo;s stored in the themes/zafta/layouts/partials/ directory.\nCreate the Header and Footer Partials # In Hugo, a partial is a sugar-coated template. Normally a template reference has a path specified. Partials are different. Hugo searches for them along a TODO defined search path. This makes it easier for end-users to override the theme\u0026rsquo;s presentation.\n$ vi themes/zafta/layouts/partials/header.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; :wq $ vi themes/zafta/layouts/partials/footer.html \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq Update the Home Page Template to Use the Partials # The most noticeable difference between a template call and a partials call is the lack of path:\n{{ template \u0026#34;theme/partials/header.html\u0026#34; . }} versus\n{{ partial \u0026#34;header.html\u0026#34; . }} Both pass in the context.\nLet\u0026rsquo;s change the home page template to use these new partials.\n$ vi themes/zafta/layouts/index.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026#34;post\u0026#34;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if or (eq .Type \u0026#34;page\u0026#34;) (eq .Type \u0026#34;about\u0026#34;) }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Type }} - {{ .Title }} - {{ .RelPermalink }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Generate the web site and verify the results. The title on the home page is now \u0026ldquo;your title here\u0026rdquo;, which comes from the \u0026ldquo;title\u0026rdquo; variable in the config.toml file.\nUpdate the Default Single Template to Use the Partials # $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Generate the web site and verify the results. The title on the posts and the about page should both reflect the value in the markdown file.\nAdd “Date Published” to Posts # It\u0026rsquo;s common to have posts display the date that they were written or published, so let\u0026rsquo;s add that. The front matter of our posts has a variable named \u0026ldquo;date.\u0026rdquo; It\u0026rsquo;s usually the date the content was created, but let\u0026rsquo;s pretend that\u0026rsquo;s the value we want to display.\nAdd “Date Published” to the Template # We\u0026rsquo;ll start by updating the template used to render the posts. The template code will look like:\n{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }} Posts use the default single template, so we\u0026rsquo;ll change that file.\n$ vi themes/zafta/layouts/_default/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Generate the web site and verify the results. The posts now have the date displayed in them. There\u0026rsquo;s a problem, though. The \u0026ldquo;about\u0026rdquo; page also has the date displayed.\nAs usual, there are a couple of ways to make the date display only on posts. We could do an \u0026ldquo;if\u0026rdquo; statement like we did on the home page. Another way would be to create a separate template for posts.\nThe \u0026ldquo;if\u0026rdquo; solution works for sites that have just a couple of content types. It aligns with the principle of \u0026ldquo;code for today,\u0026rdquo; too.\nLet\u0026rsquo;s assume, though, that we\u0026rsquo;ve made our site so complex that we feel we have to create a new template type. In Hugo-speak, we\u0026rsquo;re going to create a section template.\nLet\u0026rsquo;s restore the default single template before we forget.\n$ mkdir themes/zafta/layouts/post $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Now we\u0026rsquo;ll update the post\u0026rsquo;s version of the single template. If you remember Hugo\u0026rsquo;s rules, the template engine will use this version over the default.\n$ vi themes/zafta/layouts/post/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Note that we removed the date logic from the default template and put it in the post template. Generate the web site and verify the results. Posts have dates and the about page doesn\u0026rsquo;t.\nDon\u0026rsquo;t Repeat Yourself # DRY is a good design goal and Hugo does a great job supporting it. Part of the art of a good template is knowing when to add a new template and when to update an existing one. While you\u0026rsquo;re figuring that out, accept that you\u0026rsquo;ll be doing some refactoring. Hugo makes that easy and fast, so it\u0026rsquo;s okay to delay splitting up a template.\n"},{"id":2,"href":"/posts/goisforlovers/","title":"(Hu)go Template Primer","section":"Blogs","content":"Hugo uses the excellent Go html/template library for its template engine. It is an extremely lightweight engine that provides a very small amount of logic. In our experience that it is just the right amount of logic to be able to create a good static website. If you have used other template systems from different languages or frameworks you will find a lot of similarities in Go templates.\nThis document is a brief primer on using Go templates. The Go docs provide more details.\nIntroduction to Go Templates # Go templates provide an extremely simple template language. It adheres to the belief that only the most basic of logic belongs in the template or view layer. One consequence of this simplicity is that Go templates parse very quickly.\nA unique characteristic of Go templates is they are content aware. Variables and content will be sanitized depending on the context of where they are used. More details can be found in the Go docs.\nBasic Syntax # Golang templates are HTML files with the addition of variables and functions.\nGo variables and functions are accessible within {{ }}\nAccessing a predefined variable \u0026ldquo;foo\u0026rdquo;:\n{{ foo }} Parameters are separated using spaces\nCalling the add function with input of 1, 2:\n{{ add 1 2 }} Methods and fields are accessed via dot notation\nAccessing the Page Parameter \u0026ldquo;bar\u0026rdquo;\n{{ .Params.bar }} Parentheses can be used to group items together\n{{ if or (isset .Params \u0026quot;alt\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;) }} Caption {{ end }} Variables # Each Go template has a struct (object) made available to it. In hugo each template is passed either a page or a node struct depending on which type of page you are rendering. More details are available on the variables page.\nA variable is accessed by referencing the variable name.\n\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; Variables can also be defined and referenced.\n{{ $address := \u0026quot;123 Main St.\u0026quot;}} {{ $address }} Functions # Go template ship with a few functions which provide basic functionality. The Go template system also provides a mechanism for applications to extend the available functions with their own. Hugo template functions provide some additional functionality we believe are useful for building websites. Functions are called by using their name followed by the required parameters separated by spaces. Template functions cannot be added without recompiling hugo.\nExample:\n{{ add 1 2 }} Includes # When including another template you will pass to it the data it will be able to access. To pass along the current context please remember to include a trailing dot. The templates location will always be starting at the /layout/ directory within Hugo.\nExample:\n{{ template \u0026quot;chrome/header.html\u0026quot; . }} Logic # Go templates provide the most basic iteration and conditional logic.\nIteration # Just like in Go, the Go templates make heavy use of range to iterate over a map, array or slice. The following are different examples of how to use range.\nExample 1: Using Context\n{{ range array }} {{ . }} {{ end }} Example 2: Declaring value variable name\n{{range $element := array}} {{ $element }} {{ end }} Example 2: Declaring key and value variable name\n{{range $index, $element := array}} {{ $index }} {{ $element }} {{ end }} Conditionals # If, else, with, or, \u0026amp; and provide the framework for handling conditional logic in Go Templates. Like range, each statement is closed with end.\nGo Templates treat the following values as false:\nfalse 0 any array, slice, map, or string of length zero Example 1: If\n{{ if isset .Params \u0026quot;title\u0026quot; }}\u0026lt;h4\u0026gt;{{ index .Params \u0026quot;title\u0026quot; }}\u0026lt;/h4\u0026gt;{{ end }} Example 2: If -\u0026gt; Else\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{else}} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }} Example 3: And \u0026amp; Or\n{{ if and (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}} Example 4: With\nAn alternative way of writing \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent.\nThe first example above could be simplified as:\n{{ with .Params.title }}\u0026lt;h4\u0026gt;{{ . }}\u0026lt;/h4\u0026gt;{{ end }} Example 5: If -\u0026gt; Else If\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{ else if isset .Params \u0026quot;caption\u0026quot; }} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }} Pipes # One of the most powerful components of Go templates is the ability to stack actions one after another. This is done by using pipes. Borrowed from unix pipes, the concept is simple, each pipeline\u0026rsquo;s output becomes the input of the following pipe.\nBecause of the very simple syntax of Go templates, the pipe is essential to being able to chain together function calls. One limitation of the pipes is that they only can work with a single value and that value becomes the last parameter of the next pipeline.\nA few simple examples should help convey how to use the pipe.\nExample 1 :\n{{ if eq 1 1 }} Same {{ end }} is the same as\n{{ eq 1 1 | if }} Same {{ end }} It does look odd to place the if at the end, but it does provide a good illustration of how to use the pipes.\nExample 2 :\n{{ index .Params \u0026quot;disqus_url\u0026quot; | html }} Access the page parameter called \u0026ldquo;disqus_url\u0026rdquo; and escape the HTML.\nExample 3 :\n{{ if or (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}} Stuff Here {{ end }} Could be rewritten as\n{{ isset .Params \u0026quot;caption\u0026quot; | or isset .Params \u0026quot;title\u0026quot; | or isset .Params \u0026quot;attr\u0026quot; | if }} Stuff Here {{ end }} Context (aka. the dot) # The most easily overlooked concept to understand about Go templates is that {{ . }} always refers to the current context. In the top level of your template this will be the data set made available to it. Inside of a iteration it will have the value of the current item. When inside of a loop the context has changed. . will no longer refer to the data available to the entire page. If you need to access this from within the loop you will likely want to set it to a variable instead of depending on the context.\nExample:\n{{ $title := .Site.Title }} {{ range .Params.tags }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026quot;{{ $baseurl }}/tags/{{ . | urlize }}\u0026quot;\u0026gt;{{ . }}\u0026lt;/a\u0026gt; - {{ $title }} \u0026lt;/li\u0026gt; {{ end }} Notice how once we have entered the loop the value of {{ . }} has changed. We have defined a variable outside of the loop so we have access to it from within the loop.\nHugo Parameters # Hugo provides the option of passing values to the template language through the site configuration (for sitewide values), or through the meta data of each specific piece of content. You can define any values of any type (supported by your front matter/config format) and use them however you want to inside of your templates.\nUsing Content (page) Parameters # In each piece of content you can provide variables to be used by the templates. This happens in the front matter.\nAn example of this is used in this documentation site. Most of the pages benefit from having the table of contents provided. Sometimes the TOC just doesn\u0026rsquo;t make a lot of sense. We\u0026rsquo;ve defined a variable in our front matter of some pages to turn off the TOC from being displayed.\nHere is the example front matter:\n--- title: \u0026#34;Permalinks\u0026#34; date: \u0026#34;2013-11-18\u0026#34; aliases: - \u0026#34;/doc/permalinks/\u0026#34; groups: [\u0026#34;extras\u0026#34;] groups_weight: 30 notoc: true --- Here is the corresponding code inside of the template:\n{{ if not .Params.notoc }} \u0026lt;div id=\u0026quot;toc\u0026quot; class=\u0026quot;well col-md-4 col-sm-6\u0026quot;\u0026gt; {{ .TableOfContents }} \u0026lt;/div\u0026gt; {{ end }} Using Site (config) Parameters # In your top-level configuration file (eg, config.yaml) you can define site parameters, which are values which will be available to you in chrome.\nFor instance, you might declare:\nparams: CopyrightHTML: \u0026#34;Copyright \u0026amp;#xA9; 2013 John Doe. All Rights Reserved.\u0026#34; TwitterUser: \u0026#34;spf13\u0026#34; SidebarRecentLimit: 5 Within a footer layout, you might then declare a \u0026lt;footer\u0026gt; which is only provided if the CopyrightHTML parameter is provided, and if it is given, you would declare it to be HTML-safe, so that the HTML entity is not escaped again. This would let you easily update just your top-level config file each January 1st, instead of hunting through your templates.\n{{if .Site.Params.CopyrightHTML}}\u0026lt;footer\u0026gt; \u0026lt;div class=\u0026#34;text-center\u0026#34;\u0026gt;{{.Site.Params.CopyrightHTML | safeHtml}}\u0026lt;/div\u0026gt; \u0026lt;/footer\u0026gt;{{end}} An alternative way of writing the \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent:\n{{with .Site.Params.TwitterUser}}\u0026lt;span class=\u0026#34;twitter\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;https://twitter.com/{{.}}\u0026#34; rel=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;/images/twitter.png\u0026#34; width=\u0026#34;48\u0026#34; height=\u0026#34;48\u0026#34; title=\u0026#34;Twitter: {{.}}\u0026#34; alt=\u0026#34;Twitter\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt;{{end}} Finally, if you want to pull \u0026ldquo;magic constants\u0026rdquo; out of your layouts, you can do so, such as in this example:\n\u0026lt;nav class=\u0026#34;recent\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Recent Posts\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt;{{range first .Site.Params.SidebarRecentLimit .Site.Recent}} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{.RelPermalink}}\u0026#34;\u0026gt;{{.Title}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {{end}}\u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; "},{"id":3,"href":"/posts/hugoisforlovers/","title":"Getting Started with Hugo","section":"Blogs","content":" Step 1. Install Hugo # Go to Hugo releases and download the appropriate version for your OS and architecture.\nSave it somewhere specific as we will be using it in the next step.\nMore complete instructions are available at Install Hugo\nStep 2. Build the Docs # Hugo has its own example site which happens to also be the documentation site you are reading right now.\nFollow the following steps:\nClone the Hugo repository Go into the repo Run hugo in server mode and build the docs Open your browser to http://localhost:1313 Corresponding pseudo commands:\ngit clone https://github.com/spf13/hugo cd hugo /path/to/where/you/installed/hugo server --source=./docs \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Press ctrl+c to stop Once you\u0026rsquo;ve gotten here, follow along the rest of this page on your local build.\nStep 3. Change the docs site # Stop the Hugo process by hitting Ctrl+C.\nNow we are going to run hugo again, but this time with hugo in watch mode.\n/path/to/hugo/from/step/1/hugo server --source=./docs --watch \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Watching for changes in /Users/spf13/Code/hugo/docs/content \u0026gt; Press ctrl+c to stop Open your favorite editor and change one of the source content pages. How about changing this very file to fix the typo. How about changing this very file to fix the typo.\nContent files are found in docs/content/. Unless otherwise specified, files are located at the same relative location as the url, in our case docs/content/overview/quickstart.md.\nChange and save this file.. Notice what happened in your terminal.\n\u0026gt; Change detected, rebuilding site \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 26 ms Refresh the browser and observe that the typo is now fixed.\nNotice how quick that was. Try to refresh the site before it\u0026rsquo;s finished building. I double dare you. Having nearly instant feedback enables you to have your creativity flow without waiting for long builds.\nStep 4. Have fun # The best way to learn something is to play with it.\n"},{"id":4,"href":"/cheatsheet/bash/","title":"Bash","section":"Cheatsheet","content":" Bash # #Getting started # hello.sh # #!/bin/bash VAR=\u0026#34;world\u0026#34; echo \u0026#34;Hello $VAR!\u0026#34; # =\u0026gt; Hello world! Execute the script\n$ bash hello.sh Variables # NAME=\u0026#34;John\u0026#34; echo ${NAME} # =\u0026gt; John echo $NAME # =\u0026gt; John echo \u0026#34;$NAME\u0026#34; # =\u0026gt; John echo \u0026#39;$NAME\u0026#39; # =\u0026gt; $NAME echo \u0026#34;${NAME}!\u0026#34; # =\u0026gt; John! NAME = \u0026#34;John\u0026#34; # =\u0026gt; Error (about space) Comments # # This is an inline Bash comment. : \u0026#39; This is a very neat comment in bash \u0026#39; Multi-line comments use :' to open and ' to close\nArguments # $1 … $9 Parameter 1 \u0026hellip; 9 $0 Name of the script itself $1 First argument ${10} Positional parameter 10 $# Number of arguments $$ Process id of the shell $* All arguments $@ All arguments, starting from first $- Current options $_ Last argument of the previous command See: Special parameters.\nFunctions # get_name() { echo \u0026#34;John\u0026#34; } echo \u0026#34;You are $(get_name)\u0026#34; See: Functions\nConditionals # if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi See: Conditionals\nBrace expansion # echo {A,B}.js {A,B} Same as A B {A,B}.js Same as A.js B.js {1..5} Same as 1 2 3 4 5 See: Brace expansion\nShell execution # echo \u0026#34;I\u0026#39;m in $(PWD)\u0026#34; # Same echo \u0026#34;I\u0026#39;m in `pwd`\u0026#34; See: Command substitution\n#Parameter expansions # Syntax # ${FOO%suffix} Remove suffix ${FOO#prefix} Remove prefix ${FOO%%suffix} Remove long suffix ${FOO##prefix} Remove long prefix ${FOO/from/to} Replace first match ${FOO//from/to} Replace all ${FOO/%from/to} Replace suffix ${FOO/#from/to} Replace prefix Substrings\n${FOO:0:3} Substring (position, length) ${FOO:(-3):3} Substring from the right Length\n${#FOO} Length of $FOO Default values\n${FOO:-val} $FOO, or val if unset ${FOO:=val} Set $FOO to val if unset ${FOO:+val} val if $FOO is set ${FOO:?message} Show message and exit if $FOO is unset Substitution # echo ${food:-Cake} #=\u0026gt; $food or \u0026#34;Cake\u0026#34; STR=\u0026#34;/path/to/foo.cpp\u0026#34; echo ${STR%.cpp} # /path/to/foo echo ${STR%.cpp}.o # /path/to/foo.o echo ${STR%/*} # /path/to echo ${STR##*.} # cpp (extension) echo ${STR##*/} # foo.cpp (basepath) echo ${STR#*/} # path/to/foo.cpp echo ${STR##*/} # foo.cpp echo ${STR/foo/bar} # /path/to/bar.cpp Slicing # name=\u0026#34;John\u0026#34; echo ${name} # =\u0026gt; John echo ${name:0:2} # =\u0026gt; Jo echo ${name::2} # =\u0026gt; Jo echo ${name::-1} # =\u0026gt; Joh echo ${name:(-1)} # =\u0026gt; n echo ${name:(-2)} # =\u0026gt; hn echo ${name:(-2):2} # =\u0026gt; hn length=2 echo ${name:0:length} # =\u0026gt; Jo See: Parameter expansion\nbasepath \u0026amp; dirpath # SRC=\u0026#34;/path/to/foo.cpp\u0026#34; BASEPATH=${SRC##*/} echo $BASEPATH # =\u0026gt; \u0026#34;foo.cpp\u0026#34; DIRPATH=${SRC%$BASEPATH} echo $DIRPATH # =\u0026gt; \u0026#34;/path/to/\u0026#34; Transform # STR=\u0026#34;HELLO WORLD!\u0026#34; echo ${STR,} # =\u0026gt; hELLO WORLD! echo ${STR,,} # =\u0026gt; hello world! STR=\u0026#34;hello world!\u0026#34; echo ${STR^} # =\u0026gt; Hello world! echo ${STR^^} # =\u0026gt; HELLO WORLD! ARR=(hello World) echo \u0026#34;${ARR[@],}\u0026#34; # =\u0026gt; hello world echo \u0026#34;${ARR[@]^}\u0026#34; # =\u0026gt; Hello World #Arrays # Defining arrays # Fruits=(\u0026#39;Apple\u0026#39; \u0026#39;Banana\u0026#39; \u0026#39;Orange\u0026#39;) Fruits[0]=\u0026#34;Apple\u0026#34; Fruits[1]=\u0026#34;Banana\u0026#34; Fruits[2]=\u0026#34;Orange\u0026#34; ARRAY2=(foo{1..2}) # =\u0026gt; foo1 foo2 ARRAY3=({A..D}) # =\u0026gt; A B C D # declare construct declare -a Numbers=(1 2 3 4 5 6) Indexing # ${Fruits[0]} First element ${Fruits[-1]} Last element ${Fruits[*]} All elements ${Fruits[@]} All elements ${#Fruits[@]} Number of all ${#Fruits} Length of 1st ${#Fruits[3]} Length of nth ${Fruits[@]:3:2} Range ${!Fruits[@]} Keys of all Iteration # Fruits=(\u0026#39;Apple\u0026#39; \u0026#39;Banana\u0026#39; \u0026#39;Orange\u0026#39;) for e in \u0026#34;${Fruits[@]}\u0026#34;; do echo $e done With index\nfor i in \u0026#34;${!Fruits[@]}\u0026#34;; do printf \u0026#34;%s\\t%s\\n\u0026#34; \u0026#34;$i\u0026#34; \u0026#34;${Fruits[$i]}\u0026#34; done Operations # Fruits=(\u0026#34;${Fruits[@]}\u0026#34; \u0026#34;Watermelon\u0026#34;) # Push Fruits+=(\u0026#39;Watermelon\u0026#39;) # Also Push Fruits=( ${Fruits[@]/Ap*/} ) # Remove by regex match unset Fruits[2] # Remove one item Fruits=(\u0026#34;${Fruits[@]}\u0026#34;) # Duplicate Fruits=(\u0026#34;${Fruits[@]}\u0026#34; \u0026#34;${Veggies[@]}\u0026#34;) # Concatenate lines=(`cat \u0026#34;logfile\u0026#34;`) # Read from file Arrays as arguments # function extract() { local -n myarray=$1 local idx=$2 echo \u0026#34;${myarray[$idx]}\u0026#34; } Fruits=(\u0026#39;Apple\u0026#39; \u0026#39;Banana\u0026#39; \u0026#39;Orange\u0026#39;) extract Fruits 2 # =\u0026gt; Orangle #Dictionaries # Defining # declare -A sounds sounds[dog]=\u0026#34;bark\u0026#34; sounds[cow]=\u0026#34;moo\u0026#34; sounds[bird]=\u0026#34;tweet\u0026#34; sounds[wolf]=\u0026#34;howl\u0026#34; Working with dictionaries # echo ${sounds[dog]} # Dog\u0026#39;s sound echo ${sounds[@]} # All values echo ${!sounds[@]} # All keys echo ${#sounds[@]} # Number of elements unset sounds[dog] # Delete dog Iteration # for val in \u0026#34;${sounds[@]}\u0026#34;; do echo $val done for key in \u0026#34;${!sounds[@]}\u0026#34;; do echo $key done #Conditionals # Integer conditions # [[ NUM -eq NUM ]] Equal [[ NUM -ne NUM ]] Not equal [[ NUM -lt NUM ]] Less than [[ NUM -le NUM ]] Less than or equal [[ NUM -gt NUM ]] Greater than [[ NUM -ge NUM ]] Greater than or equal (( NUM \u0026lt; NUM )) Less than (( NUM \u0026lt;= NUM )) Less than or equal (( NUM \u0026gt; NUM )) Greater than (( NUM \u0026gt;= NUM )) Greater than or equal String conditions # [[ -z STR ]] Empty string [[ -n STR ]] Not empty string [[ STR == STR ]] Equal [[ STR = STR ]] Equal (Same above) [[ STR \u0026lt; STR ]] Less than (ASCII) [[ STR \u0026gt; STR ]] Greater than (ASCII) [[ STR != STR ]] Not Equal [[ STR =~ STR ]] Regexp Example # String\nif [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; else echo \u0026#34;This never happens\u0026#34; fi Combinations\nif [[ X \u0026amp;\u0026amp; Y ]]; then ... fi Equal\nif [[ \u0026#34;$A\u0026#34; == \u0026#34;$B\u0026#34; ]]; then ... fi Regex\nif [[ \u0026#39;1. abc\u0026#39; =~ ([a-z]+) ]]; then echo ${BASH_REMATCH[1]} fi Smaller\nif (( $a \u0026lt; $b )); then echo \u0026#34;$a is smaller than $b\u0026#34; fi Exists\nif [[ -e \u0026#34;file.txt\u0026#34; ]]; then echo \u0026#34;file exists\u0026#34; fi File conditions # [[ -e FILE ]] Exists [[ -d FILE ]] Directory [[ -f FILE ]] File [[ -h FILE ]] Symlink [[ -s FILE ]] Size is \u0026gt; 0 bytes [[ -r FILE ]] Readable [[ -w FILE ]] Writable [[ -x FILE ]] Executable [[ f1 -nt f2 ]] f1 newer than f2 [[ f1 -ot f2 ]] f2 older than f1 [[ f1 -ef f2 ]] Same files More conditions # [[ -o noclobber ]] If OPTION is enabled [[ ! EXPR ]] Not [[ X \u0026amp;\u0026amp; Y ]] And `[[ X logical and, or # if [ \u0026#34;$1\u0026#34; = \u0026#39;y\u0026#39; -a $2 -gt 0 ]; then echo \u0026#34;yes\u0026#34; fi if [ \u0026#34;$1\u0026#34; = \u0026#39;n\u0026#39; -o $2 -lt 0 ]; then echo \u0026#34;no\u0026#34; fi #Loops # Basic for loop # for i in /etc/rc.*; do echo $i done C-like for loop # for ((i = 0 ; i \u0026lt; 100 ; i++)); do echo $i done Ranges # for i in {1..5}; do echo \u0026#34;Welcome $i\u0026#34; done With step size\nfor i in {5..50..5}; do echo \u0026#34;Welcome $i\u0026#34; done Auto increment # i=1 while [[ $i -lt 4 ]]; do echo \u0026#34;Number: $i\u0026#34; ((i++)) done Auto decrement # i=3 while [[ $i -gt 0 ]]; do echo \u0026#34;Number: $i\u0026#34; ((i--)) done Continue # for number in $(seq 1 3); do if [[ $number == 2 ]]; then continue; fi echo \u0026#34;$number\u0026#34; done Break # for number in $(seq 1 3); do if [[ $number == 2 ]]; then # Skip entire rest of loop. break; fi # This will only print 1 echo \u0026#34;$number\u0026#34; done Until # count=0 until [ $count -gt 10 ]; do echo \u0026#34;$count\u0026#34; ((count++)) done Forever # while true; do # here is some code. done Forever (shorthand) # while :; do # here is some code. done Reading lines # cat file.txt | while read line; do echo $line done #Functions # Defining functions # myfunc() { echo \u0026#34;hello $1\u0026#34; } # Same as above (alternate syntax) function myfunc() { echo \u0026#34;hello $1\u0026#34; } myfunc \u0026#34;John\u0026#34; Returning values # myfunc() { local myresult=\u0026#39;some value\u0026#39; echo $myresult } result=\u0026#34;$(myfunc)\u0026#34; Raising errors # myfunc() { return 1 } if myfunc; then echo \u0026#34;success\u0026#34; else echo \u0026#34;failure\u0026#34; fi #Options # Options # # Avoid overlay files # (echo \u0026#34;hi\u0026#34; \u0026gt; foo) set -o noclobber # Used to exit upon error # avoiding cascading errors set -o errexit # Unveils hidden failures set -o pipefail # Exposes unset variables set -o nounset Glob options # # Non-matching globs are removed # (\u0026#39;*.foo\u0026#39; =\u0026gt; \u0026#39;\u0026#39;) shopt -s nullglob # Non-matching globs throw errors shopt -s failglob # Case insensitive globs shopt -s nocaseglob # Wildcards match dotfiles # (\u0026#34;*.sh\u0026#34; =\u0026gt; \u0026#34;.foo.sh\u0026#34;) shopt -s dotglob # Allow ** for recursive matches # (\u0026#39;lib/**/*.rb\u0026#39; =\u0026gt; \u0026#39;lib/a/b/c.rb\u0026#39;) shopt -s globstar #History # Commands # history Show history shopt -s histverify Don\u0026rsquo;t execute expanded result immediately Expansions # !$ Expand last parameter of most recent command !* Expand all parameters of most recent command !-n Expand nth most recent command !n Expand nth command in history !\u0026lt;command\u0026gt; Expand most recent invocation of command \u0026lt;command\u0026gt; Operations # !! Execute last command again !!:s/\u0026lt;FROM\u0026gt;/\u0026lt;TO\u0026gt;/ Replace first occurrence of \u0026lt;FROM\u0026gt; to \u0026lt;TO\u0026gt; in most recent command !!:gs/\u0026lt;FROM\u0026gt;/\u0026lt;TO\u0026gt;/ Replace all occurrences of \u0026lt;FROM\u0026gt; to \u0026lt;TO\u0026gt; in most recent command !$:t Expand only basename from last parameter of most recent command !$:h Expand only directory from last parameter of most recent command !! and !$ can be replaced with any valid expansion.\nSlices # !!:n Expand only nth token from most recent command (command is 0; first argument is 1) !^ Expand first argument from most recent command !$ Expand last token from most recent command !!:n-m Expand range of tokens from most recent command !!:n-$ Expand nth token to last from most recent command !! can be replaced with any valid expansion i.e. !cat, !-2, !42, etc.\n#Miscellaneous # Numeric calculations # $((a + 200)) # Add 200 to $a $(($RANDOM%200)) # Random number 0..199 Subshells # (cd somedir; echo \u0026#34;I\u0026#39;m now in $PWD\u0026#34;) pwd # still in first directory Inspecting commands # command -V cd #=\u0026gt; \u0026#34;cd is a function/alias/whatever\u0026#34; Redirection # python hello.py \u0026gt; output.txt # stdout to (file) python hello.py \u0026gt;\u0026gt; output.txt # stdout to (file), append python hello.py 2\u0026gt; error.log # stderr to (file) python hello.py 2\u0026gt;\u0026amp;1 # stderr to stdout python hello.py 2\u0026gt;/dev/null # stderr to (null) python hello.py \u0026amp;\u0026gt;/dev/null # stdout and stderr to (null) python hello.py \u0026lt; foo.txt # feed foo.txt to stdin for python Source relative # source \u0026#34;${0%/*}/../share/foo.sh\u0026#34; Directory of script # DIR=\u0026#34;${0%/*}\u0026#34; Case/switch # case \u0026#34;$1\u0026#34; in start | up) vagrant up ;; *) echo \u0026#34;Usage: $0 {start|stop|ssh}\u0026#34; ;; esac Trap errors # trap \u0026#39;echo Error at about $LINENO\u0026#39; ERR or\ntraperr() { echo \u0026#34;ERROR: ${BASH_SOURCE[1]} at about ${BASH_LINENO[0]}\u0026#34; } set -o errtrace trap traperr ERR printf # printf \u0026#34;Hello %s, I\u0026#39;m %s\u0026#34; Sven Olga #=\u0026gt; \u0026#34;Hello Sven, I\u0026#39;m Olga printf \u0026#34;1 + 1 = %d\u0026#34; 2 #=\u0026gt; \u0026#34;1 + 1 = 2\u0026#34; printf \u0026#34;Print a float: %f\u0026#34; 2 #=\u0026gt; \u0026#34;Print a float: 2.000000\u0026#34; Getting options # while [[ \u0026#34;$1\u0026#34; =~ ^- \u0026amp;\u0026amp; ! \u0026#34;$1\u0026#34; == \u0026#34;--\u0026#34; ]]; do case $1 in -V | --version ) echo $version exit ;; -s | --string ) shift; string=$1 ;; -f | --flag ) flag=1 ;; esac; shift; done if [[ \u0026#34;$1\u0026#34; == \u0026#39;--\u0026#39; ]]; then shift; fi Check for command\u0026rsquo;s result # if ping -c 1 google.com; then echo \u0026#34;It appears you have a working internet connection\u0026#34; fi Special variables # $? Exit status of last task $! PID of last background task $$ PID of shell $0 Filename of the shell script See Special parameters.\nGrep check # if grep -q \u0026#39;foo\u0026#39; ~/.bash_history; then echo \u0026#34;You appear to have typed \u0026#39;foo\u0026#39; in the past\u0026#34; fi Backslash escapes # ! \u0026quot; # \u0026amp; ' ( ) , ; \u0026lt; \u0026gt; [ | \\ ] ^ { } ` $ * ? Escape these special characters with \\\nHeredoc # cat \u0026lt;\u0026lt;END hello world END Go to previous directory # pwd # /home/user/foo cd bar/ pwd # /home/user/foo/bar cd - pwd # /home/user/foo Reading input # echo -n \u0026#34;Proceed? [y/n]: \u0026#34; read ans echo $ans read -n 1 ans # Just one character Conditional execution # git commit \u0026amp;\u0026amp; git push git commit || echo \u0026#34;Commit failed\u0026#34; Strict mode # set -euo pipefail IFS=$\u0026#39;\\n\\t\u0026#39; See: Unofficial bash strict mode\n"},{"id":5,"href":"/cheatsheet/docker-cheatsheet/","title":"Docker Cheatsheet","section":"Cheatsheet","content":" Docker # #Getting started # Getting started # Create and run a container in background\n$ docker run -d -p 80:80 docker/getting-started -d - Run the container in detached mode -p 80:80 - Map port 80 to port 80 in the container docker/getting-started - The image to use Create and run a container in foreground\n$ docker run -it -p 8001:8080 --name my-nginx nginx -it - Interactive bash mode -p 8001:8080 - Map port 8001 to port 8080 in the container --name my-nginx - Specify a name nginx - The image to use General commands # docker ps List running containers docker ps -a List all containers docker ps -s List running containers (with CPU / memory) docker images List all images docker exec -it \u0026lt;container\u0026gt; bash Connecting to container docker logs \u0026lt;container\u0026gt; Shows container\u0026rsquo;s console log docker stop \u0026lt;container\u0026gt; Stop a container docker restart \u0026lt;container\u0026gt; Restart a container docker rm \u0026lt;container\u0026gt; Remove a container docker port \u0026lt;container\u0026gt; Shows container\u0026rsquo;s port mapping docker top \u0026lt;container\u0026gt; List processes docker kill \u0026lt;container\u0026gt; Kill a container Parameter \u0026lt;container\u0026gt; can be container id or name\n#Containers # Starting \u0026amp; Stopping # docker start nginx-server Starting docker stop nginx-server Stopping docker restart nginx-server Restarting docker pause nginx-server Pausing docker unpause nginx-server Unpausing docker wait nginx-server Blocking a Container docker kill nginx-server Sending a SIGKILL docker attach nginx-server Connecting to an Existing Container Information # docker ps List running containers docker ps -a List all containers docker logs nginx-server Container Logs docker inspect nginx-server Inspecting Containers docker events nginx-server Containers Events docker port nginx-server Public Ports docker top nginx-server Running Processes docker stats nginx-server Container Resource Usage docker diff nginx-server Lists the changes made to a container. Creating # docker create [options] IMAGE -a, --attach # attach stdout/err -i, --interactive # attach stdin (interactive) -t, --tty # pseudo-tty --name NAME # name your image -p, --publish 5000:5000 # port map (host:container) --expose 5432 # expose a port to containers -P, --publish-all # publish all ports --link container:alias # linking -v, --volume `pwd`:/app # mount (absolute paths needed) -e, --env NAME=hello # env vars Example\n$ docker create --name my_redis --expose 6379 redis:3.0.2 Manipulating # Renaming a Container\ndocker rename my-nginx nginx-server Removing a Container\ndocker rm nginx-server Updating a Container\ndocker update --cpu-shares 512 -m 300M nginx-server #Images # Manipulating # docker images Listing images docker rmi nginx Removing an image docker load \u0026lt; ubuntu.tar.gz Loading a tarred repository docker load --input ubuntu.tar Loading a tarred repository docker save busybox \u0026gt; ubuntu.tar Save an image to a tar archive docker history Showing the history of an image docker commit nginx Save a container as an image. docker tag nginx eon01/nginx Tagging an image docker push eon01/nginx Pushing an image Building Images # $ docker build . $ docker build github.com/creack/docker-firefox $ docker build - \u0026lt; Dockerfile $ docker build - \u0026lt; context.tar.gz $ docker build -t eon/nginx-server . $ docker build -f myOtherDockerfile . $ curl example.com/remote/Dockerfile | docker build -f - . #Networking # Manipulating # Removing a network\ndocker network rm MyOverlayNetwork Listing networks\ndocker network ls Getting information about a network\ndocker network inspect MyOverlayNetwork Connecting a running container to a network\ndocker network connect MyOverlayNetwork nginx Connecting a container to a network when it starts\ndocker run -it -d --network=MyOverlayNetwork nginx Disconnecting a container from a network\ndocker network disconnect MyOverlayNetwork nginx Creating Networks # docker network create -d overlay MyOverlayNetwork docker network create -d bridge MyBridgeNetwork docker network create -d overlay \\ --subnet=192.168.0.0/16 \\ --subnet=192.170.0.0/16 \\ --gateway=192.168.0.100 \\ --gateway=192.170.0.100 \\ --ip-range=192.168.1.0/24 \\ --aux-address=\u0026#34;my-router=192.168.1.5\u0026#34; \\ --aux-address=\u0026#34;my-switch=192.168.1.6\u0026#34; \\ --aux-address=\u0026#34;my-printer=192.170.1.5\u0026#34; \\ --aux-address=\u0026#34;my-nas=192.170.1.6\u0026#34; \\ MyOverlayNetwork #Miscellaneous # Docker Hub # docker search search_word Search docker hub for images. docker pull user/image Downloads an image from docker hub. docker login Authenticate to docker hub docker push user/image Uploads an image to docker hub. Registry commands # Login to a Registry\n$ docker login $ docker login localhost:8080 Logout from a Registry\n$ docker logout $ docker logout localhost:8080 Searching an Image\n$ docker search nginx $ docker search nginx --stars=3 --no-trunc busybox Pulling an Image\n$ docker pull nginx $ docker pull eon01/nginx localhost:5000/myadmin/nginx Pushing an Image\n$ docker push eon01/nginx $ docker push eon01/nginx localhost:5000/myadmin/nginx Batch clean # docker stop -f $(docker ps -a -q) Stopping all containers docker rm -f $(docker ps -a -q) Removing all containers docker rmi -f $(docker images -q) Removing all images Volumes # Check volumes\n$ docker volume ls Cleanup unused volumes\n$ docker volume prune "},{"id":6,"href":"/cheatsheet/grep/","title":"Grep","section":"Cheatsheet","content":" Grep # #Getting started # Usage # Search standard output (i.e. a stream of text)\n$ grep [options] search_string Search for an exact string in file:\n$ grep [options] search_string path/to/file Print lines in myfile.txt containing the string \u0026ldquo;mellon\u0026rdquo;\n$ grep \u0026#39;mellon\u0026#39; myfile.txt Wildcards are accepted in filename.\nOption examples # -i grep -i ^DA demo.txt Forgets about case sensitivity -w grep -w \u0026ldquo;of\u0026rdquo; demo.txt Search only for the full word -A grep -A 3 \u0026lsquo;Exception\u0026rsquo; error.log Display 3 lines after matching string -B grep -B 4 \u0026lsquo;Exception\u0026rsquo; error.log Display 4 lines before matching string -C grep -C 5 \u0026lsquo;Exception\u0026rsquo; error.log Display 5 lines around matching string -r grep -r \u0026lsquo;quickref.me\u0026rsquo; /var/log/nginx/ Recursive search (within subdirs) -v grep -v \u0026lsquo;warning\u0026rsquo; /var/log/syslog Return all lines which don\u0026rsquo;t match the pattern -e grep -e \u0026lsquo;^al\u0026rsquo; filename Use regex (lines starting with \u0026lsquo;al\u0026rsquo;) -E grep -E \u0026lsquo;ja(s|cks)on\u0026rsquo; filename Extended regex (lines containing jason or jackson) -c grep -c \u0026rsquo;error\u0026rsquo; /var/log/syslog Count the number of matches -l grep -l \u0026lsquo;robot\u0026rsquo; /var/log/* Print the name of the file(s) of matches -o grep -o search_string filename Only show the matching part of the string -n grep -n \u0026ldquo;go\u0026rdquo; demo.txt Show the line numbers of the matches #Basic regular expressions # Refer # Regex syntax (quickref.me) Regex examples (quickref.me) Please refer to the full version of the regex cheat sheet for more complex requirements.\nWildcards # . Any character. ? Optional and can only occur once. * Optional and can occur more than once. + Required and can occur more than once. Quantifiers # {n} Previous item appears exactly n times. {n,} Previous item appears n times or more. {,m} Previous item appears n times maximum. {n,m} Previous item appears between n and m times. POSIX # [:alpha:] Any lower and upper case letter. [:digit:] Any number. [:alnum:] Any lower and upper case letter or digit. [:space:] Any whites­pace. Character # [A-Z­a-z] Any lower and upper case letter. [0-9] Any number. [0-9­A-Z­a-z] Any lower and upper case letter or digit. Position # ^ Beginning of line. $ End of line. ^$ Empty line. \\\u0026lt; Start of word. \\\u0026gt; End of word. "},{"id":7,"href":"/ci-cd/argocd/ArgoCD-cheatsheet/","title":"Argo Cd Cheatsheet","section":"Argocd","content":" CLI Usage # argo list # List workflows argo submit [--watch] myworkflow.yaml # Create workflow argo submit myworkflow.yaml -p foo=bar # Create workflow with parameters argo submit myworkflow.yaml --parameter-file config.yaml argo submit myworkflow.yaml --entry-point \u0026quot;my-command\u0026quot; argo logs \u0026lt;pod\u0026gt; # Show workflow log argo delete \u0026lt;pod\u0026gt; # Delete workflow argo delete --all # Delete all workflows You can also use kubectl\nkubectl get wf # List workflows kubectl delete wf \u0026lt;name\u0026gt; # Delete workflow Simple Workflow # apiVersion: argoproj.io/v1alpha1 kind: Workflow # new type of k8s spec metadata: generateName: hello-world- # name of the workflow spec spec: entrypoint: whalesay # invoke the whalesay template templates: - name: whalesay # name of the template container: image: docker/whalesay command: [cowsay] args: [\u0026quot;{{inputs.parameters.message}}\u0026quot;] resources: # limit the resources limits: memory: 32Mi cpu: 100m Multi-Step Workflow # apiVersion: argoproj.io/v1alpha1 kind: Workflow [...] spec: [...] templates: - name: my-template steps: - - name: step1 # \u0026lt;- Note the list in list structure! template: [...] arguments: parameters: - [...] - - name: step2a [...] - name: step2b [...] Execution of the defined steps happens by traversing the list tree. All elements of a tree leaf run in parallel while the first level list does define the steps sequence.\nSteps with Loops # steps: - - name: print-message template: whalesay arguments: parameters: - name: message value: \u0026quot;{{item}}\u0026quot; withItems: # invoke whalesay once for each item in parallel - hello world # item 1 - goodbye world # item 2 Steps: Conditional Execution # steps: # flip a coin - - name: flip-coin template: flip-coin # evaluate the result in parallel - - name: heads template: heads # call heads template if \u0026quot;heads\u0026quot; when: \u0026quot;{{steps.flip-coin.outputs.result}} == heads\u0026quot; - name: tails template: tails # call tails template if \u0026quot;tails\u0026quot; when: \u0026quot;{{steps.flip-coin.outputs.result}} == tails\u0026quot; Steps: Running scripts # spec: templates: - name: flip-coin script: image: python:alpine3.6 command: [python] source: | import random result = \u0026quot;heads\u0026quot; if random.randint(0,1) == 0 else \u0026quot;tails\u0026quot; print(result) "},{"id":8,"href":"/ci-cd/jenkins/Jenkins-deploy-AWS-ECS/","title":"Jenkins Deploy Aws Ecs","section":"Jenkins","content":" Jenkins deploy AWS ECS # Jenkins deploy AWS ECS\n{% code title=\u0026ldquo;Jenkinsfile\u0026rdquo; %}\nnode { ws(\u0026#34;workspace/${env.JOB_NAME}/${env.BRANCH_NAME}\u0026#34;) { try { def imageTag def serviceName def taskFamily def dockerFilePrefix def clusterName def envName if (env.BRANCH_NAME == \u0026#34;dev\u0026#34;) { imageTag = \u0026#34;\u0026#34; serviceName = \u0026#34;\u0026#34; taskFamily = \u0026#34;\u0026#34; dockerFilePrefix = \u0026#34;\u0026#34; clusterName = \u0026#34;\u0026#34; envName = \u0026#34;\u0026#34; } if (env.BRANCH_NAME == \u0026#34;prod\u0026#34;) { imageTag = \u0026#34;\u0026#34; serviceName = \u0026#34;\u0026#34; taskFamily = \u0026#34;\u0026#34; dockerFilePrefix = \u0026#34;\u0026#34; clusterName = \u0026#34;\u0026#34; envName = \u0026#34;\u0026#34; } // Notify slack, new build started! stage(\u0026#34;BUILD STARTED\u0026#34;) { slackSend (username: \u0026#39;CI\u0026#39;, channel: \u0026#34;slack-channel\u0026#34;, color: \u0026#39;#FFFF00\u0026#39;, message: \u0026#34;STARTED: Job \u0026#39;${env.JOB_NAME} [${env.BUILD_NUMBER}]\u0026#39; (${env.BUILD_URL})\u0026#34;) } def remoteImageTag = \u0026#34;${imageTag}:${BUILD_NUMBER}\u0026#34; def taskDefile = \u0026#34;file://aws/task-definition-${BUILD_NUMBER}.json\u0026#34; def ecRegistry = \u0026#34;https://your-aws-acc.dkr.ecr.ap-southeast-1.amazonaws.com\u0026#34; def nodeHome = tool name: \u0026#34;nodejs13\u0026#34;, type: \u0026#34;jenkins.plugins.nodejs.tools.NodeJSInstallation\u0026#34; env.PATH = \u0026#34;${nodeHome}/bin:${env.PATH}\u0026#34; stage(\u0026#34;Checkout\u0026#34;) { checkout scm } stage(\u0026#34;Docker build\u0026#34;) { sh \u0026#34;docker build -t your-aws-acc.dkr.ecr.ap-southeast-1.amazonaws.com/${remoteImageTag} \\ -f ${dockerFilePrefix}.Dockerfile .\u0026#34; } stage(\u0026#34;Docker push\u0026#34;) { sh \u0026#34;aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin your-aws-acc.dkr.ecr.ap-southeast-1.amazonaws.com/${remoteImageTag}\u0026#34; sh \u0026#34;docker push your-aws-acc.dkr.ecr.ap-southeast-1.amazonaws.com/${remoteImageTag}\u0026#34; } stage(\u0026#34;Deploy\u0026#34;) { sh \u0026#34;cp -f /var/jenkins_home/workspace/${clusterName}_td.json aws/task-definition.json\u0026#34; sh \u0026#34; \\ sed -e \u0026#39;s;%BUILD_TAG%;${BUILD_NUMBER};g\u0026#39; \\ aws/task-definition.json \u0026gt; \\ aws/task-definition-${BUILD_NUMBER}.json \\ \u0026#34; // Register the new [TaskDefinition] sh \u0026#34; \\ aws ecs register-task-definition --family ${taskFamily} \\ --cli-input-json ${taskDefile} \\ \u0026gt; /dev/null \\ \u0026#34; // Get the last registered [TaskDefinition#revision] def taskRevision = sh ( returnStdout: true, script: \u0026#34; \\ aws ecs describe-task-definition --task-definition ${taskFamily} \\ | egrep \u0026#39;TASKDEFINITION\u0026#39; \\ | awk \u0026#39;{print \\$4}\u0026#39; \\ \u0026#34; ).trim() // ECS update service to use the newly registered [TaskDefinition#revision] // sh \u0026#34; \\ aws ecs update-service --cluster ${clusterName} \\ --service ${serviceName} \\ --task-definition ${taskFamily}:${taskRevision} \\ --desired-count 1 \\ --force-new-deployment \\ \u0026#34; } stage(\u0026#34;BUILD SUCCEED\u0026#34;) { slackSend (username: \u0026#39;CI\u0026#39;, channel: \u0026#34;slack-channel\u0026#34;, color: \u0026#39;#00FF00\u0026#39;, message: \u0026#34;SUCCESSFUL: Job \u0026#39;${env.JOB_NAME} [${env.BUILD_NUMBER}]\u0026#39; (${env.BUILD_URL})\u0026#34;) } } catch(e) { slackSend (username: \u0026#39;CI\u0026#39;, channel: \u0026#34;slack-channel\u0026#34;, color: \u0026#39;#FF0000\u0026#39;, message: \u0026#34;FAILED: Job \u0026#39;${env.JOB_NAME} [${env.BUILD_NUMBER}]\u0026#39; (${env.BUILD_URL})\u0026#34;) throw e } } } {% endcode %}\n"},{"id":9,"href":"/ci-cd/jenkins/jenkins-fix-report-cannot-view-on-browser/","title":"Jenkins Fix Report Cannot View on Browser","section":"Jenkins","content":" Jenkins fix report cannot view on browser # System.setProperty(\u0026#34;hudson.model.DirectoryBrowserSupport.CSP\u0026#34;, \u0026#34;style-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39;;\u0026#34;) "},{"id":10,"href":"/cloud-provider/aws/extend-the-file-system-of-ebs-volumes/","title":"Extend the File System of Ebs Volumes","section":"Aws","content":" Extend the file system of EBS volumes # To extend the file system of EBS volumes # Check disk [root@ip-10-69-13-54 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 100G 0 disk └─xvda1 202:1 0 100G 0 part / For volumes that have a partition, such as the volumes shown in the previous step, use the growpart command to extend the partition. Notice that there is a space between the device name and the partition number. sudo growpart /dev/xvda 1 sudo resize2fs /dev/xvda1 "},{"id":11,"href":"/cloud-provider/aws/Install-docker-docker-compose-on-AWS-EC2/","title":"Install Docker, Docker Compose on Aws Ec2","section":"Aws","content":" Install docker, docker-compose on AWS EC2 # {% code title=\u0026ldquo;install-ec2.sh\u0026rdquo; %}\nyum install docker git -y sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.27.0/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose systemctl start docker systemctl enable docker sudo dd if=/dev/zero of=/swapfile bs=128M count=32 sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile echo \u0026#34;/swapfile swap swap defaults 0 0\u0026#34; \u0026gt;\u0026gt; /etc/fstab {% endcode %}\n"},{"id":12,"href":"/cloud-provider/aws/install-cert-bot-ssl-letsencrypt-on-amz-linux-2/","title":"Install Cert Bot Ssl Letsencrypt on Amz Linux 2","section":"Aws","content":" Install cert bot ssl let\u0026rsquo;sencrypt on amz linux 2 # Install epel \u0026amp; certbot (for nginx)\nsudo amazon-linux-extras install epel sudo yum install certbot-nginx Get a free ssl cert, make sure to set your server IP point to your domain before hand.\nsudo certbot --nginx -d your.domain.com Setup auto renew\nSome Certbot packages do something like this to ensure it runs at a more random time (twice a day):\n0 */12 * * * perl -e \u0026#39;sleep int(rand(3600))\u0026#39; \u0026amp;\u0026amp; /usr/bin/certbot -q renew "},{"id":13,"href":"/cloud-provider/aws/mount-new-ebs-volume-to-aws-ec2/","title":"Mount New Ebs Volume to Aws Ec2","section":"Aws","content":" Mount new EBS volume to AWS EC2 # The root device is /dev/xvda. The attached volume is /dev/xvdb, which is not yet mounted.\n[ec2-user ~]$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 8G 0 disk -xvda1 202:1 0 8G 0 part / xvdb 202:80 0 10G 0 disk TL;DR\nsudo mkfs -t xfs /dev/xvdb sudo mkdir /data sudo mount /dev/xvdb /data ls -la /data "},{"id":14,"href":"/cloud-provider/aws/setting-swap-ec2/","title":"Setting Swap Ec2","section":"Aws","content":" Setting Swap EC2 # In this example dd command, the swap file is 4 GB (128 MB x 32):\nsudo dd if=/dev/zero of=/swapfile bs=128M count=32 sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile sudo swapon -s echo \u0026#34;/swapfile swap swap defaults 0 0\u0026#34; \u0026gt;\u0026gt; /etc/fstab "},{"id":15,"href":"/cloud-provider/azure/azure-new-service-update/","title":"Azure New Service Update","section":"Azure","content":" Azure new service update # 15.0.0 - 2042-12-03 # Fixed # Removed humans, they weren\u0026rsquo;t doing fine with animals. Changed # Animals are now super cute, all of them. 14.0.0 - 2042-10-06 # Added # Introduced animals into the world, we believe they\u0026rsquo;re going to be a neat addition. "},{"id":16,"href":"/cloud-provider/gcp/mistakes-to-avoid-when-using-google-cloud/","title":"Mistakes to Avoid When Using Google Cloud","section":"Gcp","content":" Mistakes to avoid when using Google Cloud # Google Cloud Platform is a suite of public cloud computing services offered by Google. The platform includes a range of hosted services for compute, storage and application development that run on Google hardware. Google Cloud Platform services can be used by software developers, cloud administrators and other enterprise IT professionals.\nAvoid excessive use of default service accounts and primitive roles # IAM stands for identity and Access management[1], and it allows you to manage access control by defining who (identity) has what access (role) to which resources. Cloud IAM has many predefined roles. Most of these roles provide appropriate access to suit your needs and the most common use cases. Well, not always.\nWhen you enable or use some Google Cloud services, they create user-managed service accounts that allow them to deploy jobs, that access other Google Cloud resources. These accounts are known as default service accounts. Convenient, right? Unfortunately, it is not as bright as you\u0026rsquo;d imagine, the default service account practically always use primitive roles that has too extensive rights, i.e. Editor.\nPermissions matrix\nSource: https://storage.googleapis.com/gweb-cloudblog-publish/images/zGbQytQs1Ez.max-700x700.png\n\u0026ldquo;Primitive roles\u0026rdquo; like Owner and Editor grant wide-ranging access to all project resources. Your newly launched service now has access to all resources in your project. This is totally safe, right? (No, no it\u0026rsquo;s not).\nIs it?\nAlways use the minimum required, limit permissions to only those you need:\nAs a first step, we strongly suggest disabling the automatic addition of permissions for the default service accounts[2] Use a custom service account. Create a separate service account for each logical element in your infrastructure, such as an instance group or application. This will reduce the risk of abuse of rights, and will give you greater control over the rights of individual component. Granulation will allow precise adjustment of entitlements to a specific service - the minimum required. Use custom roles. Create a role that contains only the required permissions. Your application usually has to read something from the bucket, it doesn\u0026rsquo;t need to manage all the buckets in the project. Permissions allow users to perform specific actions on Google Cloud resources[3], and usually look like this: service.resource.verb --- compute.instances.list compute instances.stop storage.objects.get storage.objects.list A basic example of a custom role could look like this:\nIs it?\nAdditional tip - Searching for the appropriate permissions can often be inconvenient, when working with legacy code. The recommendations engine may be helpful. Using separate accounts, Recommender will check which roles have been used for the last 90 days and propose an appropriate set of permissions. [4]\nFlawed VPC design # VPC - Virtual Private Cloud. You can think of a VPC network the same way you\u0026rsquo;d think of a physical network, except that it is virtualized within Google Cloud. Within a VPC you create and manage typical network resources such as subnets, firewall rules, routes and more.\nAs with the previous point, when creating a project, GCP generates a default setup, with basic settings and a few firewall rules. Unfortunately, the pre-populated rules in the default network allow for a wide range of insecurities:\ndefault-allow-internal - Allows ingress connections for all protocols and ports among instances in the network. This rule has the second-to-lowest priority of 65534, and it effectively permits incoming connections to VM instances from others in the same network. This rule allows traffic in 10.128.0.0/9 (from 10.128.0.1 to 10.255.255.254), a range that covers all subnets in the network. default-allow-ssh - Allows ingress connections on TCP destination port 22 from any source to any instance in the network. This rule has a priority of 65534. default-allow-rdp - Allows ingress connections on TCP destination port 3389 from any source to any instance in the network. This rule has a priority of 65534, and it enables connections to instances running the Microsoft Remote Desktop Protocol (RDP). default-allow-icmp - Allows ingress ICMP traffic from any source to any instance in the network. This rule has a priority of 65534, and it enables tools such as ping. These defaults are predictable, permissive, and inflict unnecessary risk towards your environment. For your safety, we suggest deleting these rules and making your own, depending on your needs. Follow the minimum required rule.\nSubnets are also created automatically, in each region, with predefined IP ranges. It is neither necessary nor convenient. You don\u0026rsquo;t have to use every region in the world, you don\u0026rsquo;t want to have the same IP ranges in every VPC. Why? If you plan to connect multiple VPC using for example VPC Network Peering or VPN, you may encounter a problem with overlapping IP addresses.\nConsider VPC network design early. In many cases, the project grows very quickly and you can forget about such things\u0026hellip; Unfortunately, this approach in network configuration causes more problems than you can imagine. Sometimes needed changes will require resource recreation in a different region or an entirely different implementation. It\u0026rsquo;s worth rethinking your network architecture beforehand, there are some good rules for it:\nNaming convention - make your network resource names understandable and maintainable. Group services into separate subnets. Think about allocation/reservation of IP scopes for multiple VPCs - to prevent overlapping. Consider advantages and disadvantages of different connection or routing propagation methods[5], in some cases this can have a huge impact on the network architecture. Single project, single VPC network\nSource: https://cloud.google.com/architecture/images/vpc-bps-single-project-single-vpc.svg\nNeglecting network features # By default, all VMs in GCP are assigned a public IP address and are therefore accessible directly from the internet if there are firewall rules that allows it (such as the default ones). External IP address also allows external communication - access to internet, depending on the environment it is required or not. A safe and convenient approach is to use a NAT gateway, in this case Cloud NAT service. There are several benefits associated with it, especially in production environments:\nSecurity - You easily mitigate the problem of exposing services publicly. Availability - Cloud NAT is a distributed, software-defined managed service. It doesn\u0026rsquo;t depend on any VMs in your project or a single physical gateway device. Scalabillity - You can scale the number of NAT IP addresses that it uses. Fixed external IP addresses - An example of why you might need fixed outbound IP addresses is the case in which a third party allows requests from specific external IP addresses. OK, we have abandoned external IP addresses in favor of the NAT service, but how do we get to communicate with the instance that has no external IP address? In this configuration, we can only use another instance on the same network or VPN connection[6]\nBastion host\nAnother secure setup proposal is commonly called bastion host - an external endpoint that allows your clients to SSH from the public internet. With this set-up, your application can be safely kept away from public eyes. You can use the bastion in several ways, the most common one is called \u0026ldquo;Jump server\u0026rdquo;. By using ssh forwarding you can get to the target machine. [7]. Remember that you should also secure the bastion\u0026rsquo;s ssh, to avoid trouble - our article about Shell security should prove itself useful here.[8]\nBastion\nSource: https://cloud.google.com/solutions/images/bastion.png\nThe second approach that is often used, is to set up a VPN server such as OpenVPN/Pritunl on the bastion. This allows the configuration and adaptation of access through these services, for example:\nExternal auth integration 2FA - Two-factor authentication Roles/polices to access specific subnets Conclusion - what to do? # Apply the principle of least privilege to service accounts. Remove the insecure defaults of VPCs. Consider VPC network design early. You can provision your VMs without public IPs, reducing the attack surface. Use NAT GW for outbound traffic. Securely connect to VM instances using bastion. REF: https://sysdogs.com/articles/common-mistakes-to-avoid-gcp\n"},{"id":17,"href":"/containers/docker/Best-practices-for-building-containers/","title":"Best Practices for Building Containers","section":"Docker","content":" Best practices for building containers # Dockerfile tips and tricks # Consider the example below.\nFROM debian # Copy application files COPY . /app # Install required system packages RUN apt-get update RUN apt-get -y install imagemagick curl software-properties-common gnupg vim ssh RUN curl -sL https://deb.nodesource.com/setup_10.x | bash - RUN apt-get -y install nodejs # Install NPM dependencies RUN npm install --prefix /app EXPOSE 80 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;--prefix\u0026#34;, \u0026#34;app\u0026#34;] It takes 127.8 seconds to build the image and it is 554MB. Let\u0026rsquo;s improve this result by following some good practices!!\n1- Order matters for caching # The least frequently changing statements should be appear first. This is because when you change or modify a line in the dockerfile and its cache gets invalidated, the subsequent line will break due to these changes. Hence, you need to keep the most frequently changing lines as last as possible.\nFROM debian # Install required system packages RUN apt-get update RUN apt-get -y install imagemagick curl software-properties-common gnupg vim ssh RUN curl -sL https://deb.nodesource.com/setup_10.x | bash - RUN apt-get -y install nodejs # Copy application files COPY . /app # Install NPM dependencies RUN npm install --prefix /app EXPOSE 80 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;--prefix\u0026#34;, \u0026#34;app\u0026#34;] Rebuild the image using the same command, but avoiding the installation of the system packages. This is the result: it takes 5.8 seconds to build!! The improvement is huge!!\n2- ****You should be more specific about the files you copy to make sure that you are not invalidating the cache with changes that do not affect the application. # FROM debian # Install required system packages RUN apt-get update RUN apt-get -y install imagemagick curl software-properties-common gnupg vim ssh RUN curl -sL https://deb.nodesource.com/setup_10.x | bash - RUN apt-get -y install nodejs # Copy application files COPY package.json server.js /app # Install NPM dependencies RUN npm install --prefix /app EXPOSE 80 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;--prefix\u0026#34;, \u0026#34;app\u0026#34;] NOTE: Use \u0026ldquo;COPY\u0026rdquo; instead of \u0026ldquo;ADD\u0026rdquo; when possible. Both commands do basically the same thing, but \u0026ldquo;ADD\u0026rdquo; is more complex: it has extra features like extracting files or copying them from remote sources. From a security perspective too, using \u0026ldquo;ADD\u0026rdquo; increases the risk of malware injection in your image if the remote source you are using is unverified or insecure.\n3- Avoiding packaging dependencies that you do not need # The current Dockerfile includes the ssh system package. However, you can access your containers using the docker exec command instead of ssh\u0026rsquo;ing into them. Apart from that, it also includes vim for debugging purposes, which can be installed when required, instead of packaged by default. Both packages are removable from the image.\nIn addition, you can configure the package manager to avoid installing packages that you don\u0026rsquo;t need. To do so, use the --no-install-recommends flag on your apt-get calls:\nFROM debian # Install required system packages RUN apt-get update RUN apt-get -y install --no-install-recommends imagemagick curl software-properties-common gnupg RUN curl -sL https://deb.nodesource.com/setup_10.x | bash - RUN apt-get -y install --no-install-recommends nodejs # Copy application files COPY package.json server.js /app # Install NPM dependencies RUN npm install --prefix /app EXPOSE 80 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;--prefix\u0026#34;, \u0026#34;app\u0026#34;] 4- Try to chain all the cacheable units. # FROM debian # Install required system packages RUN apt-get update \u0026amp;\u0026amp; apt-get -y install --no-install-recommends imagemagick curl software-properties-common gnupg \\ \u0026amp;\u0026amp; curl -sL https://deb.nodesource.com/setup_10.x | bash - \u0026amp;\u0026amp; apt-get -y install --no-install-recommends nodejs # Copy application files COPY package.json server.js /app # Install NPM dependencies RUN npm install --prefix /app EXPOSE 80 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;--prefix\u0026#34;, \u0026#34;app\u0026#34;] 5- Finally, remove the package manager cache to reduce the image size # FROM debian # Install required system packages RUN apt-get update \u0026amp;\u0026amp; apt-get -y install --no-install-recommends imagemagick curl software-properties-common gnupg \\ \u0026amp;\u0026amp; curl -sL https://deb.nodesource.com/setup_10.x | bash - \u0026amp;\u0026amp; apt-get -y install --no-install-recommends nodejs \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # Copy application files COPY package.json server.js /app # Install NPM dependencies RUN npm install --prefix /app EXPOSE 80 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;--prefix\u0026#34;, \u0026#34;app\u0026#34;] If you rebuild the image again…\n$ docker build . -t express-image:0.0.3 … The image was reduced to 340MB!! That\u0026rsquo;s almost half of its original size.\n"},{"id":18,"href":"/containers/docker/checking-file-when-build-docker/","title":"Checking File When Build Docker","section":"Docker","content":" Checking file when build docker # Build this Dockerfile\nFROM busybox RUN mkdir /tmp/build/ COPY . /tmp/build/ RUN du -ah tmp/build | sort -n -r | head -n 100 docker build . "},{"id":19,"href":"/containers/docker/disstroless-docker-image/","title":"Disstroless Docker Image","section":"Docker","content":" Disstroless docker image # FROM golang:1.12 as build-env WORKDIR /go/src/app ADD . /go/src/app RUN go get -d -v ./... RUN go build -o /go/bin/app FROM gcr.io/distroless/base COPY --from=build-env /go/bin/app / CMD [\u0026#34;/app\u0026#34;] "},{"id":20,"href":"/containers/docker/docker-how-to-cleanup-unused-resources/","title":"Docker How to Cleanup Unused Resources","section":"Docker","content":" Docker - How to cleanup (unused) resources # Docker - How to cleanup (unused) resources # Once in a while, you may need to cleanup resources (containers, volumes, images, networks) \u0026hellip;\ndelete volumes # // see: https://github.com/chadoe/docker-cleanup-volumes $ docker volume rm $(docker volume ls -qf dangling=true) $ docker volume ls -qf dangling=true | xargs -r docker volume rm delete networks # $ docker network ls $ docker network ls | grep \u0026#34;bridge\u0026#34; $ docker network rm $(docker network ls | grep \u0026#34;bridge\u0026#34; | awk \u0026#39;/ / { print $1 }\u0026#39;) remove docker images # // see: http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images $ docker images $ docker rmi $(docker images --filter \u0026#34;dangling=true\u0026#34; -q --no-trunc) $ docker images | grep \u0026#34;none\u0026#34; $ docker rmi $(docker images | grep \u0026#34;none\u0026#34; | awk \u0026#39;/ / { print $3 }\u0026#39;) remove docker containers # // see: http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images $ docker ps $ docker ps -a $ docker rm $(docker ps -qa --no-trunc --filter \u0026#34;status=exited\u0026#34;) Resize disk space for docker vm # $ docker-machine create --driver virtualbox --virtualbox-disk-size \u0026#34;40000\u0026#34; default "},{"id":21,"href":"/containers/docker/quick-install-docker/","title":"Quick Install Docker","section":"Docker","content":" Quick install docker # install docker with yum:\n$ yum install docker add your user to docker group to able run docker command\n$ sudo usermod -a -G docker your_user make sure docker run on start up\nsystemctl enable docker service docker start "},{"id":22,"href":"/containers/docker/remove-unused-docker-resource/","title":"Remove Unused Docker Resource","section":"Docker","content":" Remove unused docker resource # TL;DR # remove all the things, such as images, container, network:\n$ docker system prune stop all container running:\n$ docker stop $(docker ps -q) remove all container:\n$ docker rm $(docker ps -a -q) remove unused volumes:\n$ docker volume prune remove unused images:\n$ docker image prune "},{"id":23,"href":"/containers/k8s/kubectl-tips-and-tricks/","title":"Kubectl Tips and Tricks","section":"K8s","content":" Kubectl productivity # Kubectl alias:\nSome of the 800 generated aliases are:\nalias k=\u0026#39;kubectl\u0026#39; alias kg=\u0026#39;kubectl get\u0026#39; alias kgpo=\u0026#39;kubectl get pod\u0026#39; alias ksysgpo=\u0026#39;kubectl --namespace=kube-system get pod\u0026#39; alias krm=\u0026#39;kubectl delete\u0026#39; alias krmf=\u0026#39;kubectl delete -f\u0026#39; alias krming=\u0026#39;kubectl delete ingress\u0026#39; alias krmingl=\u0026#39;kubectl delete ingress -l\u0026#39; alias krmingall=\u0026#39;kubectl delete ingress --all-namespaces\u0026#39; alias kgsvcoyaml=\u0026#39;kubectl get service -o=yaml\u0026#39; alias kgsvcwn=\u0026#39;watch kubectl get service --namespace\u0026#39; alias kgsvcslwn=\u0026#39;watch kubectl get service --show-labels --namespace\u0026#39; Install:\nwget https://raw.githubusercontent.com/ahmetb/kubectl-aliases/master/.kubectl_aliases echo \u0026#34;source ~/.kubectl_aliases\u0026#34; \u0026gt;\u0026gt; .zshrc # get all pods sort by name\nkubectl get po -o jsonpath='{range.items[*]}{.metadata.name}{\u0026quot;\\n\u0026quot;}{end}'\n# Get all pods, which as restart_count \u0026gt; 0\n**kubectl get po -o jsonpath='{range.items[?(@.status.containerStatuses[0].restartCount\u0026gt;0)]}{.status.containerStatuses[0].name}{\u0026quot;\\n\u0026quot;}{end}'\n# Get all non-running pods\nkubectl get po -o jsonpath='{range.items[?(@.status.phase != \u0026quot;Running\u0026quot;)]}{.metadata.name}{\u0026quot;\\n\u0026quot;}{end}'\n# Get most used cpu pods\nkubectl top pods | tail -n +2 | sort -nr -k 2 | awk '{print $1}' | head -n 1\n# Get all nodes, and their IP\nkubectl get no -o jsonpath='{range.items[*]}{.metadata.name}{\u0026quot;\\t\u0026quot;}{.status.addresses[?(@.type==\u0026quot;InternalIP\u0026quot;)].address}{\u0026quot;\\n\u0026quot;}{end}'**\n"},{"id":24,"href":"/containers/k8s/Linkerd-Cheatsheet/","title":"Linkerd Cheatsheet","section":"K8s","content":" Linkerd Cheatsheet # Uninject # Remove the Linkerd proxy from a Kubernetes config.\nYou can uninject resources contained in a single file, inside a folder and its sub-folders, or coming from stdin.\nExamples # # Uninject all the deployments in the default namespace. kubectl get deploy -o yaml | linkerd uninject - | kubectl apply -f - # Download a resource and uninject it through stdin. curl http://url.to/yml | linkerd uninject - | kubectl apply -f - # Uninject all the resources inside a folder and its sub-folders. linkerd uninject \u0026lt;folder\u0026gt; | kubectl apply -f - "},{"id":25,"href":"/containers/k8s/quick-scale-deployment-accross-namespaces/","title":"Quick Scale Deployment Accross Namespaces","section":"K8s","content":" quick scale deployment accross namespaces # k get deploy | awk \u0026#39;NR \u0026gt; 1 {print $1}\u0026#39; | xargs -n1 kubectl scale deploy --replicas=0 "},{"id":26,"href":"/databases/General-Table-Size-Information/","title":"General Table Size Information","section":"Databases","content":" Postgres General Table Size Information # This will report size information for all tables, in both raw bytes and \u0026ldquo;pretty\u0026rdquo; form.\nSELECT *, pg_size_pretty(total_bytes) AS total , pg_size_pretty(index_bytes) AS index , pg_size_pretty(toast_bytes) AS toast , pg_size_pretty(table_bytes) AS table FROM ( SELECT *, total_bytes-index_bytes-coalesce(toast_bytes,0) AS table_bytes FROM ( SELECT c.oid,nspname AS table_schema, relname AS table_name , c.reltuples AS row_estimate , pg_total_relation_size(c.oid) AS total_bytes , pg_indexes_size(c.oid) AS index_bytes , pg_total_relation_size(reltoastrelid) AS toast_bytes FROM pg_class c LEFT JOIN pg_namespace n ON n.oid = c.relnamespace WHERE relkind = \u0026#39;r\u0026#39; ) a ) a; "},{"id":27,"href":"/databases/install-postgres-client-amazon-linux-1/","title":"Install Postgres Client Amazon Linux 1","section":"Databases","content":" Install postgres client Amazon Linux 1 # Getting Super Powers # Becoming a super hero is a fairly straight forward process:\nwget https://download.postgresql.org/pub/repos/yum/12/redhat/rhel-6-x86_64/postgresql12-libs-12.1-1PGDG.rhel6.x86_64.rpm wget https://download.postgresql.org/pub/repos/yum/12/redhat/rhel-6-x86_64/postgresql12-devel-12.1-1PGDG.rhel6.x86_64.rpm wget https://download.postgresql.org/pub/repos/yum/12/redhat/rhel-6-x86_64/postgresql12-12.1-1PGDG.rhel6.x86_64.rpm wget https://download.postgresql.org/pub/repos/yum/12/redhat/rhel-6-x86_64/postgresql12-server-12.1-1PGDG.rhel6.x86_64.rpm yum localinstall *.rp "},{"id":28,"href":"/databases/postgres-create-user-and-grant-permistions/","title":"Postgres Create User and Grant Permistions","section":"Databases","content":" Postgres create user and grant permistions # List all user: # \\du List all schema: # \\dn Create user read_only # create user ro_user with password \u0026#39;pass_123\u0026#39;; Grant permistion on schema # grant usage on schema common to ro_user; grant select on all tables in schema common to ro_user; ALTER DEFAULT PRIVILEGES IN SCHEMA common GRANT SELECT ON TABLES TO ro_user; "},{"id":29,"href":"/linux/check-ssl-certificate-expiration-date-s/","title":"Check Ssl Certificate Expiration Date S","section":"Linux","content":" Check SSL certificate expiration date(s) # prepare checkssl.sh file with content bellow:\n{% code title=\u0026ldquo;checkssl.sh\u0026rdquo; %}\n#!/bin/bash # By B Shea Dec2018 \u0026amp; Mar2020 # https://www.holylinux.net # Test for OpenSSL - if not installed stop here. if ! [[ -x $(which openssl) ]]; then printf \u0026#34;\\nOpenSSL not found or not executable.\\nPlease install OpenSSL before proceeding.\\n\\n\u0026#34; exit 1 fi ### user adjustable variables ### #openssl query timeout: openssl_timeout=\u0026#34;timeout 10\u0026#34; # 30 days is default on warnings - overidden on command line with \u0026#39;-d\u0026#39;: days_to_warn=30 # default name for file lists sitelist=./websites.txt ### Clear/list/set defaults for variables ### epoch_day=86400 epoch_warning=$((days_to_warn*epoch_day)) regex_numbers=\u0026#39;^[0-9]+$\u0026#39; expire=\u0026#34;0\u0026#34; website=\u0026#34;\u0026#34; port=\u0026#34;\u0026#34; tls=\u0026#34;0\u0026#34; sTLS=\u0026#34;\u0026#34; show_tls=\u0026#34;\u0026#34; certfilename=\u0026#34;\u0026#34; location=\u0026#34;\u0026#34; filename=\u0026#34;\u0026#34; displaysite=\u0026#34;\u0026#34; #COLORS color=\u0026#34;0\u0026#34; RED=$(tput setaf 1) #expired!! GREEN=$(tput setaf 2) #within bounds YELLOW=$(tput setaf 3) #warning/date close! NC=$(tput sgr0) #reset to normal # usage=\u0026#34; $(basename \u0026#34;$0\u0026#34;) [-h] [-c] [-d DAYS] [-f FILENAME] | [-w WEBSITE] | [-s SITELIST] Retrieve the expiration date(s) on SSL certificate(s) using OpenSSL. Usage: -h Help -c Color output -d Amount of days to show warnings (default is 30 days) Example: -d 15 -f SSL date from FILENAME Example: -f /home/user/example.pem -w SSL date from SITE(:PORT) (Port defaults to 443) Example: -w www.example.com -s SSL date(s) from SITELIST Example: -s ./websites.txt List format: sub.domain.tld:993 (one per line - port optional) Example: $ $(basename \u0026#34;$0\u0026#34;) -c -d 14 -s ./websites.txt WARNS (in color) if within 14 days of expiring on each entry in the file list. \u0026#34; #FUNCTIONS is_integer() { if ! [[ \u0026#34;$1\u0026#34; =~ $regex_numbers ]]; then printf \u0026#34;\\nError.\\nNot a number. You used a parameter that requires a whole number.\\n$usage\u0026#34; exit 1 fi } menu_input() { echo echo \u0026#34;1: Enter file location of certificate\u0026#34; echo \u0026#34;2: Enter an Internet site in form of subdomain.domain.tld(:port)\u0026#34; echo read -p \u0026#34;Enter 1 or 2 (anything else quits): \u0026#34; -n 1 -r echo } get_lookup_input() { location=\u0026#34;\u0026#34; echo read -p \u0026#34;Please enter the $lookuptype location: \u0026#34; location } set_format() { set_formatting=\u0026#34;%-40s%-25s\\n\u0026#34; set_formatting_green=$set_formatting set_formatting_yellow=$set_formatting set_formatting_red=$set_formatting printf \u0026#34;\\nWarning is $days_to_warn days.\\n\u0026#34; printf \u0026#34;Color is \u0026#34; if [[ $color == \u0026#34;1\u0026#34; ]]; then set_formatting_green=\u0026#34;$GREEN%-40s$NC%-25s\\n\u0026#34; set_formatting_yellow=\u0026#34;$YELLOW%-40s$NC%-25s\\n\u0026#34; set_formatting_red=\u0026#34;$RED%-40s$NC%-25s\\n\u0026#34; printf \u0026#34;enabled.\\n\\n\u0026#34; else printf \u0026#34;disabled.\\n\\n\u0026#34; fi printf \u0026#34;$set_formatting\u0026#34; \u0026#34;LOCATION\u0026#34; \u0026#34;EXPIRATION DATE\u0026#34; printf \u0026#34;$set_formatting\u0026#34; \u0026#34;--------\u0026#34; \u0026#34;---------------\u0026#34; } parse_port() { port=443 tls=\u0026#34;0\u0026#34; show_tls=\u0026#34;\u0026#34; parseurl=$(echo $website | awk \u0026#39;$1 ~ /^.*:/\u0026#39; | cut -d\u0026#39;:\u0026#39; -f1) parseport=$(echo $website | awk \u0026#39;$1 ~ /^.*:/\u0026#39; | cut -d\u0026#39;:\u0026#39; -f2) if [[ $parseport =~ $regex_numbers ]]; then # -\u0026gt; port was found website=$parseurl port=$parseport if [[ $port == \u0026#34;587\u0026#34; ]]; then # Use TLS lookup and notify show_tls=\u0026#34; (TLS)\u0026#34; tls=\u0026#34;1\u0026#34; fi fi } check_expiry() { expire=\u0026#34;0\u0026#34; # use epoch times for calcs/compares today_epoch=\u0026#34;$(gdate +%s)\u0026#34; sTLS=\u0026#34;\u0026#34; if [[ $tls == \u0026#34;1\u0026#34; ]]; then sTLS=\u0026#34; -starttls smtp\u0026#34; fi if [ \u0026#34;$lookuptype\u0026#34; == \u0026#34;FILENAME\u0026#34; ]; then expire_date=$(openssl x509 -in $certfilename$sTLS -noout -dates 2\u0026gt;/dev/null | \\ awk -F= \u0026#39;/^notAfter/ { print $2; exit }\u0026#39;) else expire_date=$($openssl_timeout openssl s_client -servername $website -connect $website:$port$sTLS \u0026lt;/dev/null 2\u0026gt;/dev/null | \\ openssl x509 -noout -dates 2\u0026gt;/dev/null | \\ awk -F= \u0026#39;/^notAfter/ { print $2; exit }\u0026#39;) fi if ! [[ -z $expire_date ]]; then # -\u0026gt; found date-process it: expire_epoch=$(gdate +%s -d \u0026#34;$expire_date\u0026#34;) timeleft=`expr $expire_epoch - $today_epoch` if [[ $timeleft -le $epoch_warning ]]; then #WARN expire=\u0026#34;1\u0026#34; fi if [[ $today_epoch -ge $expire_epoch ]]; then #EXPIRE expire=\u0026#34;2\u0026#34; fi else expire=\u0026#34;3\u0026#34; expire_date=\u0026#34;N/A \u0026#34; fi } output_site() { parse_port check_expiry if [ \u0026#34;$lookuptype\u0026#34; != \u0026#34;FILENAME\u0026#34; ]; then display_site=\u0026#34;$website:$port$show_tls\u0026#34; else display_site=\u0026#34;$filename$show_tls\u0026#34; fi if [[ $expire == \u0026#34;1\u0026#34; ]]; then printf \u0026#34;$set_formatting_yellow\u0026#34; \u0026#34;$display_site\u0026#34; \u0026#34;$expire_date !\u0026#34; # YELLOW OUTPUT - warning elif [[ $expire == \u0026#34;2\u0026#34; ]]; then printf \u0026#34;$set_formatting_red\u0026#34; \u0026#34;$display_site\u0026#34; \u0026#34;$expire_date !!\u0026#34; # RED OUTPUT - expired elif [[ $expire == \u0026#34;3\u0026#34; ]]; then printf \u0026#34;$set_formatting\u0026#34; \u0026#34;$display_site\u0026#34; \u0026#34;$expire_date !!!\u0026#34; # NO COLOR - NOT FOUND else printf \u0026#34;$set_formatting_green\u0026#34; \u0026#34;$display_site\u0026#34; \u0026#34;$expire_date\u0026#34; # GREEN OUTPUT fi } # client_lookup() { lookuptype=\u0026#34;WEBSITE\u0026#34; if [[ -z $website ]]; then #loop lookup - ask for input get_lookup_input website=$location fi set_format output_site lookuptype=\u0026#34;\u0026#34; website=\u0026#34;\u0026#34; echo } file_lookup() { lookuptype=\u0026#34;FILENAME\u0026#34; if [[ -z $certfilename ]]; then #loop lookup - ask for input get_lookup_input certfilename=$location fi filename=$(basename -- \u0026#34;$certfilename\u0026#34;) set_format output_site lookuptype=\u0026#34;\u0026#34; filename=\u0026#34;\u0026#34; echo } list_lookup() { lookuptype=\u0026#34;FILELIST\u0026#34; file_contents=$(\u0026lt;$sitelist) set_format while IFS= read -r website; do if ! [[ -z $website ]]; then output_site fi done \u0026lt;\u0026lt;\u0026lt;\u0026#34;$file_contents\u0026#34; lookuptype=\u0026#34;\u0026#34; echo } #HANDLE ARGUMENTS while getopts \u0026#39;:hcd:f:s:w:\u0026#39; option; do case \u0026#34;$option\u0026#34; in h) printf \u0026#34;$usage\u0026#34; exit 0 ;; c) color=\u0026#34;1\u0026#34; ;; d) is_integer \u0026#34;$OPTARG\u0026#34; if [ \u0026#34;$OPTARG\u0026#34; -ge 1 -a \u0026#34;$OPTARG\u0026#34; -le 365 ]; then days_to_warn=\u0026#34;$OPTARG\u0026#34; epoch_warning=$((days_to_warn*epoch_day)) else printf \u0026#34;\\nDays must be between 1 and 365\\n$usage\u0026#34; exit 1 fi ;; f) certfilename=$OPTARG [[ -r $certfilename ]] \u0026amp;\u0026amp; file_lookup || printf \u0026#34;\\nFile not found/not readable. Permissions?\\n\\n\u0026#34;; exit 1; exit 0 ;; s) sitelist=$OPTARG [[ -r $sitelist ]] \u0026amp;\u0026amp; list_lookup || printf \u0026#34;\\nFile not found/not readable. Permissions?\\n\\n\u0026#34;; exit 1; exit 0 ;; w) website=$OPTARG client_lookup exit 0 ;; :) printf \u0026#34;\\nYou specified a flag that needs an argument.\\n$usage\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 ;; *) printf \u0026#34;\\nI do not understand \u0026#39;\u0026#34;$1\u0026#34; \u0026#34;$2\u0026#34;\u0026#39;.\\n$usage\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 ;; esac done shift $((OPTIND - 1)) #LOOP RUN (default if no flags) if [ $# -eq 0 ]; then # no command line arguments/flags found printf \u0026#34;\\nNo flags used or available. Interactive mode.\\n\u0026#34; while : do menu_input if [[ $REPLY == \u0026#34;1\u0026#34; ]] then file_lookup elif [[ $REPLY == \u0026#34;2\u0026#34; ]] then client_lookup else # exit [[ \u0026#34;$0\u0026#34; = \u0026#34;$BASH_SOURCE\u0026#34; ]] \u0026amp;\u0026amp; exit 1 || return 1 fi echo done fi% {% endcode %}\nprepare website list to check with example format:\n{% code title=\u0026ldquo;websites.txt\u0026rdquo; %}\nwww.abc.com zxc.com {% endcode %}\ncheck your ssl expired date:\n./checkssl.sh -c -d 45 -s websites.txt {% hint style=\u0026ldquo;info\u0026rdquo; %} some advande usages:\ncheckssl [-h] [-c] [-d DAYS] [-f FILENAME] | [-w WEBSITE] | [-s SITELIST] Retrieve the expiration date(s) on SSL certificate(s) using OpenSSL. Usage: -h Help -c Color output -d Amount of days to show warnings (default is 30 days) Example: -d 15 -f SSL date from FILENAME Example: -f /home/user/example.pem -w SSL date from SITE(:PORT) (Port defaults to 443) Example: -w www.example.com -s SSL date(s) from SITELIST Example: -s ./websites.txt List format: sub.domain.tld:993 (one per line - port optional) Example: $ checkssl -c -d 14 -s ./websites.txt WARNS (in color) if within 14 days of expiring on each entry in the file list. {% endhint %}\nEg output:\n"},{"id":30,"href":"/linux/Convert-service-account-json-to-single-line/","title":"Convert Service Account JSON to Single Line","section":"Linux","content":" Convert service account json to single line # jq \u0026#39;.\u0026#39; service-account.json | jq -sR \u0026#39;.\u0026#39; "},{"id":31,"href":"/linux/dynamic-port-mapping-for-access-ftp-server/","title":"Dynamic Port Mapping for Access FTP Server","section":"Linux","content":" Dynamic port mapping for access FTP server # Getting Super Powers # 1/ Dynamic port mapping for access FTP server:\n$ ssh -D 2121 -N -f user@10.12.133.3 {% hint style=\u0026ldquo;info\u0026rdquo; %} Super-powers are granted randomly so please submit an issue if you\u0026rsquo;re not happy with yours. {% endhint %}\n2/ Setting sock proxy on filezila client:\n3/ Using Filezilla as normal\n"},{"id":32,"href":"/linux/print-all-duplicated/","title":"Print All Duplicated","section":"Linux","content":" Print all duplicated lines in a file # linux #awk #text processing # How to print all duplicated lines in some text file? Let me introduce awk again:\n\u0026lt; input.txt awk \u0026#39;foo[$0]++\u0026#39; "},{"id":33,"href":"/linux/quick-load-.env-file/","title":"Quick Load .Env File","section":"Linux","content":" Quick load .env file # TL;DR # Load .env and ignore comment line start with #\n$ export $(grep -v \u0026#39;^#\u0026#39; .env | xargs) For unset all of the variables defined in the file , use this:\n$ unset $(grep -v \u0026#39;^#\u0026#39; .env | sed -E \u0026#39;s/(.*)=.*/\\1/\u0026#39; | xargs) "},{"id":34,"href":"/linux/writing-bash-shell-scripts-best-practice/","title":"Writing Bash Shell Scripts Best Practice","section":"Linux","content":" Writing bash shell scripts best practice # Many people hack together shell scripts quickly to do simple tasks, but these soon take on a life of their own. Unfortunately shell scripts are full of subtle effects which result in scripts failing in unusual ways. It’s possible to write scripts which minimise these problems. In this article, I explain several techniques for writing robust bash scripts.\nUse set -u # How often have you written a script that broke because a variable wasn’t set? I know I have, many times.\nchroot=$1 ... rm -rf $chroot/usr/share/doc If you ran the script above and accidentally forgot to give a parameter, you would have just deleted all of your system documentation rather than making a smaller chroot. So what can you do about it? Fortunately bash provides you with set -u, which will exit your script if you try to use an uninitialised variable. You can also use the slightly more readable set -o nounset.\ndavid% bash /tmp/shrink-chroot.sh $chroot= david% bash -u /tmp/shrink-chroot.sh /tmp/shrink-chroot.sh: line 3: $1: unbound variable david% Use set -e # Every script you write should include set -e at the top. This tells bash that it should exit the script if any statement returns a non-true return value. The benefit of using -e is that it prevents errors snowballing into serious issues when they could have been caught earlier. Again, for readability you may want to use set -o errexit.\nUsing -e gives you error checking for free. If you forget to check something, bash will do it or you. Unfortunately it means you can’t check $? as bash will never get to the checking code if it isn’t zero. There are other constructs you could use:\ncommand if [ \u0026#34;$?\u0026#34;-ne 0]; then echo \u0026#34;command failed\u0026#34;; exit 1; fi could be replaced with\ncommand || { echo \u0026#34;command failed\u0026#34;; exit 1; } or\nif ! command; then echo \u0026#34;command failed\u0026#34;; exit 1; fi What if you have a command that returns non-zero or you are not interested in its return value? You can use command || true, or if you have a longer section of code, you can turn off the error checking, but I recommend you use this sparingly.\nset +e command1 command2 set -e On a slightly related note, by default bash takes the error status of the last item in a pipeline, which may not be what you want. For example, false | true will be considered to have succeeded. If you would like this to fail, then you can use set -o pipefail to make it fail.\nProgram defensively – expect the unexpected # Your script should take into account of the unexpected, like files missing or directories not being created. There are several things you can do to prevent errors in these situations. For example, when you create a directory, if the parent directory doesn’t exist, mkdir will return an error. If you add a -p option then mkdir will create all the parent directories before creating the requested directory. Another example is rm. If you ask rm to delete a non-existent file, it will complain and your script will terminate. (You are using -e, right?) You can fix this by using -f, which will silently continue if the file didn’t exist.\nBe prepared for spaces in filenames # Someone will always use spaces in filenames or command line arguments and you should keep this in mind when writing shell scripts. In particular you should use quotes around variables.\nif [ $filename = \u0026#34;foo\u0026#34; ]; will fail if $filename contains a space. This can be fixed by using:\nif [ \u0026#34;$filename\u0026#34; = \u0026#34;foo\u0026#34; ]; When using $@ variable, you should always quote it or any arguments containing a space will be expanded in to separate words.\ndavid% foo() { for i in $@; do printf \u0026#34;%s\\n\u0026#34; \u0026#34;$i\u0026#34;; done }; foo bar \u0026#34;baz quux\u0026#34; bar baz quux david% foo() { for i in \u0026#34;$@\u0026#34;; do printf \u0026#34;%s\\n\u0026#34; \u0026#34;$i\u0026#34;; done }; foo bar \u0026#34;baz quux\u0026#34; bar baz quux I can not think of a single place where you shouldn’t use “$@” over $@, so when in doubt, use quotes.\nIf you use find and xargs together, you should use -print0 to separate filenames with a null character rather than new lines. You then need to use -0 with xargs.\ndavid% touch \u0026#34;foo bar\u0026#34; david% find | xargs ls ls: ./foo: No such file or directory ls: bar: No such file or directory david% find -print0 | xargs -0 ls ./foo bar Setting traps # Often you write scripts which fail and leave the filesystem in an inconsistent state; things like lock files, temporary files or you’ve updated one file and there is an error updating the next file. It would be nice if you could fix these problems, either by deleting the lock files or by rolling back to a known good state when your script suffers a problem. Fortunately bash provides a way to run a command or function when it receives a unix signal using the trap command.\ntrap command signal [signal ...] There are many signals you can trap (you can get a list of them by running kill -l), but for cleaning up after problems there are only 3 we are interested in: INT, TERM and EXIT. You can also reset traps back to their default by using - as the command.\nSignal Description INT Interrupt – This signal is sent when someone kills the script by pressing ctrl-c. TERM Terminate – this signal is sent when someone sends the TERM signal using the kill command. EXIT Exit – this is a pseudo-signal and is triggered when your script exits, either through reaching the end of the script, an exit command or by a command failing when usingset -e. Usually, when you write something using a lock file you would use something like:\nif [ ! -e $lockfile ]; then touch $lockfile critical-section rm $lockfile else echo \u0026#34;critical-section is already running\u0026#34; fi What happens if someone kills your script while critical-section is running? The lockfile will be left there and your script won’t run again until it’s been deleted. The fix is to use:\nif [ ! -e $lockfile ]; then trap \u0026#34;rm -f $lockfile; exit\u0026#34; INT TERM EXIT touch $lockfile critical-section rm $lockfile trap - INT TERM EXIT else echo \u0026#34;critical-section is already running\u0026#34; fi Now when you kill the script it will delete the lock file too. Notice that we explicitly exit from the script at the end of trap command, otherwise the script will resume from the point that the signal was received.\nRace conditions # It’s worth pointing out that there is a slight race condition in the above lock example between the time we test for the lockfile and the time we create it. A possible solution to this is to use IO redirection and bash’s noclobber mode, which won’t redirect to an existing file. We can use something similar to:\nif ( set -o noclobber; echo \u0026#34;$$\u0026#34; \u0026gt; \u0026#34;$lockfile\u0026#34;) 2\u0026gt; /dev/null; then trap \u0026#39;rm -f \u0026#34;$lockfile\u0026#34;; exit $?\u0026#39; INT TERM EXIT critical-section rm -f \u0026#34;$lockfile\u0026#34; trap - INT TERM EXIT else echo \u0026#34;Failed to acquire lockfile: $lockfile.\u0026#34; echo \u0026#34;Held by $(cat $lockfile)\u0026#34; fi A slightly more complicated problem is where you need to update a bunch of files and need the script to fail gracefully if there is a problem in the middle of the update. You want to be certain that something either happened correctly or that it appears as though it didn’t happen at all.Say you had a script to add users.\nadd_to_passwd $user cp -a /etc/skel /home/$user chown $user /home/$user -R There could be problems if you ran out of diskspace or someone killed the process. In this case you’d want the user to not exist and all their files to be removed.\nrollback() { del_from_passwd $user if [ -e /home/$user ]; then rm -rf /home/$user fi exit } trap rollback INT TERM EXIT add_to_passwd $user cp -a /etc/skel /home/$user chown $user /home/$user -R trap - INT TERM EXIT We needed to remove the trap at the end or the rollback function would have been called as we exited, undoing all the script’s hard work.\nBe atomic # Sometimes you need to update a bunch of files in a directory at once, say you need to rewrite urls form one host to another on your website. You might write:\nfor file in $(find /var/www -type f -name \u0026#34;*.html\u0026#34;); do perl -pi -e \u0026#39;s/www.example.net/www.example.com/\u0026#39; $file done Now if there is a problem with the script you could have half the site referring to www.example.com and the rest referring to www.example.net. You could fix this using a backup and a trap, but you also have the problem that the site will be inconsistent during the upgrade too.\nThe solution to this is to make the changes an (almost) atomic operation. To do this make a copy of the data, make the changes in the copy, move the original out of the way and then move the copy back into place. You need to make sure that both the old and the new directories are moved to locations that are on the same partition so you can take advantage of the property of most unix filesystems that moving directories is very fast, as they only have to update the inode for that directory.\ncp -a /var/www /var/www-tmp for file in $(find /var/www-tmp -type f -name \u0026#34;*.html\u0026#34;); do perl -pi -e \u0026#39;s/www.example.net/www.example.com/\u0026#39; $file done mv /var/www /var/www-old mv /var/www-tmp /var/www This means that if there is a problem with the update, the live system is not affected. Also the time where it is affected is reduced to the time between the two mvs, which should be very minimal, as the filesystem just has to change two entries in the inodes rather than copying all the data around.\nThe disadvantage of this technique is that you need to use twice as much disk space and that any process that keeps files open for a long time will still have the old files open and not the new ones, so you would have to restart those processes if this is the case. In our example this isn’t a problem as apache opens the files every request. You can check for files with files open by using lsof. An advantage is that you now have a backup before you made your changes in case you need to revert.\nREF: https://www.davidpashley.com/articles/writing-robust-shell-scripts/\n"},{"id":35,"href":"/observability/monitoring/alert-manager/","title":"Alert Manager","section":"Monitoring","content":" Alert manager # {% code title=\u0026ldquo;alertmanager.yml\u0026rdquo; %}\nglobal: resolve_timeout: 1m slack_api_url: \u0026#39;https://hooks.slack.com/services/xxx\u0026#39; route: # When a new group of alerts is created by an incoming alert, wait at # least \u0026#39;group_wait\u0026#39; to send the initial notification. # This way ensures that you get multiple alerts for the same group that start # firing shortly after another are batched together on the first # notification. group_wait: 10s # When the first notification was sent, wait \u0026#39;group_interval\u0026#39; to send a batch # of new alerts that started firing for that group. group_interval: 15m # If an alert has successfully been sent, wait \u0026#39;repeat_interval\u0026#39; to # resend them. repeat_interval: 15m # A default receiver receiver: \u0026#34;slack-warning\u0026#34; # All the above attributes are inherited by all child routes and can # overwritten on each. routes: - receiver: \u0026#34;slack-critical\u0026#34; group_wait: 10s match_re: severity: critical continue: true group_by: [alertname, severity, app] - receiver: \u0026#34;slack-warning\u0026#34; group_wait: 10s match_re: severity: warning|info continue: true group_by: [alertname, severity, app] receivers: - name: \u0026#34;slack-critical\u0026#34; slack_configs: - api_url: \u0026#39;https://hooks.slack.com/services/xxx\u0026#39; channel: \u0026#39;alert-manager\u0026#39; color: \u0026#39;{{ template \u0026#34;slack.scs.color\u0026#34; . }}\u0026#39; title: \u0026#39;{{ template \u0026#34;slack.scs.title\u0026#34; . }}\u0026#39; text: \u0026#39;{{ template \u0026#34;slack.scs.text\u0026#34; . }}\u0026#39; send_resolved: true actions: - type: button text: \u0026#39;Runbook :green_book:\u0026#39; url: \u0026#39;{{ (index .Alerts 0).Annotations.runbook_url }}\u0026#39; - type: button text: \u0026#39;Query :mag:\u0026#39; url: \u0026#39;{{ (index .Alerts 0).GeneratorURL }}\u0026#39; - type: button text: \u0026#39;Dashboard :chart_with_upwards_trend:\u0026#39; url: \u0026#39;{{ (index .Alerts 0).Annotations.dashboard_url }}\u0026#39; - type: button text: \u0026#39;Silence :no_bell:\u0026#39; url: \u0026#39;{{ template \u0026#34;__alert_silence_link\u0026#34; . }}\u0026#39; # - type: button # text: \u0026#39;{{ template \u0026#34;slack.scs.link_button_text\u0026#34; . }}\u0026#39; # url: \u0026#39;{{ .CommonAnnotations.link_url }}\u0026#39; - name: \u0026#34;slack-warning\u0026#34; slack_configs: - api_url: \u0026#39;https://hooks.slack.com/services/xxx\u0026#39; channel: \u0026#39;alert-manager\u0026#39; color: \u0026#39;{{ template \u0026#34;slack.scs.color\u0026#34; . }}\u0026#39; title: \u0026#39;{{ template \u0026#34;slack.scs.title\u0026#34; . }}\u0026#39; text: \u0026#39;{{ template \u0026#34;slack.scs.text\u0026#34; . }}\u0026#39; send_resolved: false actions: - type: button text: \u0026#39;Runbook :green_book:\u0026#39; url: \u0026#39;{{ (index .Alerts 0).Annotations.runbook_url }}\u0026#39; - type: button text: \u0026#39;Query :mag:\u0026#39; url: \u0026#39;{{ (index .Alerts 0).GeneratorURL }}\u0026#39; - type: button text: \u0026#39;Dashboard :chart_with_upwards_trend:\u0026#39; url: \u0026#39;{{ (index .Alerts 0).Annotations.dashboard_url }}\u0026#39; - type: button text: \u0026#39;Silence :no_bell:\u0026#39; url: \u0026#39;{{ template \u0026#34;__alert_silence_link\u0026#34; . }}\u0026#39; # - type: button # text: \u0026#39;{{ template \u0026#34;slack.scs.link_button_text\u0026#34; . }}\u0026#39; # url: \u0026#39;{{ .CommonAnnotations.link_url }}\u0026#39; templates: [\u0026#39;/etc/alertmanager/templates/*.tmpl\u0026#39;] {% endcode %}\nAlert rules:\n{% tabs %} {% tab title=\u0026ldquo;backbox\u0026rdquo; %}\ngroups: - name: BlackboxGroup rules: - alert: WebDown expr: probe_success == 0 for: 2m labels: severity: critical annotations: summary: \u0026#34;{{ $labels.instance }} is down\u0026#34; description: \u0026#39;HTTP check failed\u0026#39; dashboard_url: \u0026#34;dashboard/d/UV2ducRnk/blackbox-exporter-http-prober?orgId=1\u0026#34; # - alert: BlackboxProbeHttpFailure # expr: probe_http_status_code \u0026lt;= 199 OR probe_http_status_code \u0026gt;= 400 # for: 0m # labels: # severity: critical # annotations: # summary: Blackbox probe HTTP failure (instance {{ $labels.instance }}) # description: \u0026#34;HTTP status code is not 200-399\\n VALUE = {{ $value }}\\n LABELS = {{ $labels }}\u0026#34; # - alert: BlackboxSslCertificateWillExpireSoon - alert: SSLCertExpired expr: probe_ssl_earliest_cert_expiry - time() \u0026lt; 86400 * 7 for: 2d labels: severity: warning annotations: summary: \u0026#34;SSL certificate will expire soon\u0026#34; description: \u0026#34;{{ $labels.instance }} - Remaining time: `{{ humanizeDuration $value }}`\u0026#34; dashboard_url: \u0026#34;dashboard/d/UV2ducRnk/blackbox-exporter-http-prober?orgId=1\u0026#34; - alert: SSLCertExpired expr: probe_ssl_earliest_cert_expiry - time() \u0026lt; 86400 * 3 for: 1d labels: severity: critical annotations: summary: \u0026#34;SSL certificate will expire soon\u0026#34; description: \u0026#34;{{ $labels.instance }} - Remaining time: `{{ humanizeDuration $value }}`\u0026#34; dashboard_url: \u0026#34;dashboard/d/UV2ducRnk/blackbox-exporter-http-prober?orgId=1\u0026#34; # - alert: BlackboxSslCertificateExpired # expr: probe_ssl_earliest_cert_expiry - time() \u0026lt;= 0 # for: 0m # labels: # severity: critical # annotations: # summary: Blackbox SSL certificate expired (instance {{ $labels.instance }}) # description: \u0026#34;SSL certificate has expired already\\n VALUE = {{ $value }}\\n LABELS = {{ $labels }}\u0026#34; # - alert: BlackboxProbeSlowHttp # expr: avg_over_time(probe_http_duration_seconds[1m]) \u0026gt; 1 # for: 1m # labels: # severity: warning # annotations: # summary: Blackbox probe slow HTTP (instance {{ $labels.instance }}) # description: \u0026#34;HTTP request took more than 1s\\n VALUE = {{ $value }}\\n LABELS = {{ $labels }}\u0026#34; {% endtab %}\n{% tab title=\u0026ldquo;node\u0026rdquo; %}\ngroups: - name: node_exporter rules: - alert: OutOfMemory expr: 100-(node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100) \u0026gt; 95 for: 5m labels: severity: warning annotations: summary: \u0026#34;`{{ $labels.job }}` out of RAM\u0026#34; description: \u0026#39;RAM used \u0026gt; 95% for 5mins. Current value = `{{ printf \u0026#34;%.2f\u0026#34; $value }}%`\u0026#39; dashboard_url: \u0026#34;dashboard/d/hb7fSE0Zz/scs-servers?orgId=1\u0026amp;var-job={{ $labels.job }}\u0026amp;var-hostname=All\u0026amp;var-node={{ $labels.instance }}\u0026#34; # Please add ignored mountpoints in node_exporter parameters like # \u0026#34;--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)\u0026#34;. # Same rule using \u0026#34;node_filesystem_free_bytes\u0026#34; will fire when disk fills for non-root users. - alert: OutOfDisk expr: ( 100-(node_filesystem_avail_bytes / node_filesystem_size_bytes * 100) \u0026gt; 95 and node_filesystem_readonly == 0) for: 1h labels: severity: warning annotations: summary: \u0026#34;`{{ $labels.job }}` out of disk\u0026#34; description: \u0026#39;Disk used \u0026gt; 95%. Current value `{{ printf \u0026#34;%.2f\u0026#34; $value }}%`\u0026#39; dashboard_url: \u0026#34;dashboard/d/hb7fSE0Zz/scs-servers?orgId=1\u0026amp;var-job={{ $labels.job }}\u0026amp;var-hostname=All\u0026amp;var-node={{ $labels.instance }}\u0026#34; # - alert: OutOfDisk # expr: ( 100-(node_filesystem_avail_bytes / node_filesystem_size_bytes * 100) \u0026gt; 95 and node_filesystem_readonly == 0) # for: 1h # labels: # severity: critical # annotations: # summary: \u0026#34;\u0026lt;!channel\u0026gt; `{{ $labels.job }}` out of disk\u0026#34; # description: \u0026#39;Disk used \u0026gt; 95%. Current value `{{ printf \u0026#34;%.2f\u0026#34; $value }}%`\u0026#39; # dashboard_url: \u0026#34;dashboard/d/hb7fSE0Zz/scs-servers?orgId=1\u0026amp;var-job={{ $labels.job }}\u0026amp;var-hostname=All\u0026amp;var-node={{ $labels.instance }}\u0026#34; - alert: HighCpuLoad expr: 100 - (avg by(instance,job) (rate(node_cpu_seconds_total{mode=\u0026#34;idle\u0026#34;}[5m])) * 100) \u0026gt; 95 for: 0m labels: severity: warning annotations: summary: \u0026#34;`{{ $labels.job }}` high CPU load\u0026#34; description: \u0026#39;CPU load \u0026gt; 95% for 5mins. Current value = `{{ printf \u0026#34;%.2f\u0026#34; $value }}%`\u0026#39; dashboard_url: \u0026#34;dashboard/d/hb7fSE0Zz/scs-servers?orgId=1\u0026amp;var-job={{ $labels.job }}\u0026amp;var-hostname=All\u0026amp;var-node={{ $labels.instance }}\u0026#34; {% endtab %}\n{% tab title=\u0026ldquo;template\u0026rdquo; %}\n{{ define \u0026#34;__alert_silence_link\u0026#34; -}} {{ .ExternalURL }}/#/silences/new?filter=%7B {{- range .CommonLabels.SortedPairs -}} {{- if ne .Name \u0026#34;alertname\u0026#34; -}} {{- .Name }}%3D\u0026#34;{{- .Value -}}\u0026#34;%2C%20 {{- end -}} {{- end -}} alertname%3D\u0026#34;{{- .CommonLabels.alertname -}}\u0026#34;%7D {{- end }} {{ define \u0026#34;__alert_severity\u0026#34; -}} {{- if eq .CommonLabels.severity \u0026#34;critical\u0026#34; -}} *Severity:* \u0026lt;!channel\u0026gt; `Critical` {{- else if eq .CommonLabels.severity \u0026#34;warning\u0026#34; -}} *Severity:* `Warning` {{- else if eq .CommonLabels.severity \u0026#34;info\u0026#34; -}} *Severity:* `Info` {{- else -}} *Severity:* :question: {{ .CommonLabels.severity }} {{- end }} {{- end }} {{ define \u0026#34;slack.scs.title\u0026#34; -}} [{{ .Status | toUpper -}} {{ if eq .Status \u0026#34;firing\u0026#34; }}:{{ .Alerts.Firing | len }}{{- end -}} ] {{ .CommonLabels.alertname }} {{- end }} {{ define \u0026#34;slack.scs.text\u0026#34; -}} {{ template \u0026#34;__alert_severity\u0026#34; . }} {{- if (index .Alerts 0).Annotations.summary }} {{- \u0026#34;\\n\u0026#34; -}} *Summary:* {{ (index .Alerts 0).Annotations.summary }} {{- end }} {{ range .Alerts }} {{- if .Annotations.description }} {{- \u0026#34;\\n\u0026#34; -}} {{ .Annotations.description }} {{- \u0026#34;\\n\u0026#34; -}} {{- end }} {{- if .Annotations.message }} {{- \u0026#34;\\n\u0026#34; -}} {{ .Annotations.message }} {{- \u0026#34;\\n\u0026#34; -}} {{- end }} {{- end }} {{- end }} {{ define \u0026#34;slack.scs.color\u0026#34; -}} {{ if eq .Status \u0026#34;firing\u0026#34; -}} {{ if eq .CommonLabels.severity \u0026#34;warning\u0026#34; -}} warning {{- else if eq .CommonLabels.severity \u0026#34;critical\u0026#34; -}} danger {{- else -}} #439FE0 {{- end -}} {{ else -}} good {{- end }} {{- end }} {% endtab %} {% endtabs %}\n"},{"id":36,"href":"/observability/monitoring/install-node_exporter-as-systemd/","title":"Install Node Exporter as Systemd","section":"Monitoring","content":" Install node_exporter as systemd # sudo useradd --system --shell /bin/false node_exporter curl -fsSL https://github.com/prometheus/node_exporter/releases/download/v1.1.2/node_exporter-1.1.2.linux-amd64.tar.gz \\ | sudo tar -zxvf - -C /usr/local/bin --strip-components=1 node_exporter-1.1.2.linux-amd64/node_exporter \\ \u0026amp;\u0026amp; sudo chown node_exporter:node_exporter /usr/local/bin/node_exporter sudo tee /etc/systemd/system/node_exporter.service \u0026lt;\u0026lt;\u0026#34;EOF\u0026#34; [Unit] Description=Node Exporter [Service] User=node_exporter Group=node_exporter EnvironmentFile=-/etc/sysconfig/node_exporter ExecStart=/usr/local/bin/node_exporter $OPTIONS [Install] WantedBy=multi-user.target EOF sudo systemctl daemon-reload \u0026amp;\u0026amp; \\ sudo systemctl start node_exporter \u0026amp;\u0026amp; \\ sudo systemctl status node_exporter \u0026amp;\u0026amp; \\ sudo systemctl enable node_exporter "},{"id":37,"href":"/others/alert-slack-by-hook/","title":"Alert Slack by Hook","section":"Others","content":" Alert slack by hook # Send slack alert\n#!/bin/bash curl https://hooks.slack.com/services/xxx \\ -X POST -H \u0026#34;Content-type: application/json\u0026#34; \\ -d @- \u0026lt;\u0026lt; EOF { \u0026#34;channel\u0026#34;: \u0026#34;$1\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;$2\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;danger\u0026#34;, \u0026#34;icon_emoji\u0026#34;: \u0026#34;:ghost:\u0026#34;, \u0026#34;pretext\u0026#34;: \u0026#34;$MONIT_DATE\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;$MONIT_SERVICE - $MONIT_DESCRIPTION\u0026#34; } EOF Send slack alert with RAM usage\n#!/bin/bash LOG_FILE_PATH=\u0026#34;/var/log/memory_$(date \u0026#39;+%Y-%m-%d-%H\u0026#39;).log\u0026#34; date | sudo tee -a $LOG_FILE_PATH ps -eo rss,pid,user,command | sort -rn | head -20 | awk \u0026#39;{ hr[1024**2]=\u0026#34;GB\u0026#34;; hr[1024]=\u0026#34;MB\u0026#34;; for (x=1024**3; x\u0026gt;=1024; x/=1024) { if ($1\u0026gt;=x) { printf (\u0026#34;%-6.2f %s \u0026#34;, $1/x, hr[x]); break } } } { printf (\u0026#34;%-6s %-10s \u0026#34;, $2, $3) } { for ( x=4 ; x\u0026lt;=NF ; x++ ) { printf (\u0026#34;%s \u0026#34;,$x) } print (\u0026#34;\\n\u0026#34;) }\u0026#39; | sudo tee -a $LOG_FILE_PATH memory_log=$(ps -eo rss,pid,user,command | sort -rn | head -10 | awk \u0026#39;{ hr[1024**2]=\u0026#34;GB\u0026#34;; hr[1024]=\u0026#34;MB\u0026#34;; for (x=1024**3; x\u0026gt;=1024; x/=1024) { if ($1\u0026gt;=x) { printf (\u0026#34;%-6.2f %s \u0026#34;, $1/x, hr[x]); break } } } { printf (\u0026#34;%-6s %-10s \u0026#34;, $2, $3) } { for ( x=4 ; x\u0026lt;=NF ; x++ ) { printf (\u0026#34;%s \u0026#34;,$x) } print (\u0026#34;\\n\u0026#34;) }\u0026#39;) curl https://hooks.slack.com/services/xxx \\ -X POST -H \u0026#34;Content-type: application/json\u0026#34; \\ -d @- \u0026lt;\u0026lt; EOF { \u0026#34;channel\u0026#34;: \u0026#34;$1\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;$2\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;warning\u0026#34;, \u0026#34;icon_emoji\u0026#34;: \u0026#34;:ghost:\u0026#34;, \u0026#34;pretext\u0026#34;: \u0026#34;$MONIT_SERVICE - $MONIT_DESCRIPTION\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;\\`\\`\\`$memory_log\\`\\`\\`\u0026#34;, \u0026#34;mrkdwn\u0026#34;: true } EOF "},{"id":38,"href":"/others/install-redmine-on-centos-7/","title":"Install Redmine on Centos 7","section":"Others","content":" Install redmine on centos 7 # Requirements # centos 7\n[root@new-redmine ~]# cat /etc/os-release NAME=\u0026#34;CentOS Linux\u0026#34; VERSION=\u0026#34;7 (Core)\u0026#34; ID=\u0026#34;centos\u0026#34; ID_LIKE=\u0026#34;rhel fedora\u0026#34; VERSION_ID=\u0026#34;7\u0026#34; PRETTY_NAME=\u0026#34;CentOS Linux 7 (Core)\u0026#34; mariadb 5.5.68\n[root@new-redmine ~]# mysql --version mysql Ver 15.1 Distrib 5.5.68-MariaDB, for Linux (x86_64) using readline 5.1 rbenv installed, ruby 2.5.5\n[redmine@new-redmine ~]$ rbenv --version rbenv 1.1.2-40-g62d7798 [redmine@new-redmine current]$ rbenv version 2.5.5 (set by /opt/redmine/current/.ruby-version) redmine version 4.1.1\nssh keypair setup https://docs.gitlab.com/ee/ssh/README.html\nInstall redmine # Install dependencies\nsudo yum update sudo yum install vim curl zlib-devel curl-devel openssl-devel httpd-devel apr-devel apr-util-devel mysql-devel ftp wget ImageMagick-devel gcc-c++ patch readline readline-devel zlib libyaml-devel libffi-devel make bzip2 autoconf automake libtool bison subversion sqlite-devel sudo yum install epel-release sudo yum install nginx Setup database\ninstall mariadb\nsudo yum install mariadb-server sudo systemctl start mariadb sudo systemctl enable mariadb mysql_secure_installation mysql -uroot -p create redmine database and setting password\nmysql -uroot -p MariaDB [(none)]\u0026gt; CREATE DATABASE redmine CHARACTER SET utf8; MariaDB [(none)]\u0026gt; GRANT ALL PRIVILEGES ON redmine.* TO \u0026#39;redmine\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;your-passs-\u0026#39;; MariaDB [(none)]\u0026gt; FLUSH PRIVILEGES; MariaDB [(none)]\u0026gt; \\\\q Setup user redmine, rbenv, ruby\n[root@new-redmine ~]# adduser redmine [root@new-redmine ~]# sudo su - redmine curl -sL \u0026lt;https://github.com/rbenv/rbenv-installer/raw/master/bin/rbenv-installer\u0026gt; | bash - echo \u0026#39;export PATH=\u0026#34;$HOME/.rbenv/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;eval \u0026#34;$(rbenv init -)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc Setting bashrc\n[root@new-redmine current]# cat /home/redmine/.bashrc # .bashrc # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # Uncomment the following line if you don\u0026#39;t like systemctl\u0026#39;s auto-paging feature: # export SYSTEMD_PAGER= export PG_DATABASE=redmine export PG_USERNAME=redmine export PG_PASSWORD=your-passs- export PG_HOST=localhost export RACK_ENV=\u0026#34;production\u0026#34; export RAILS_ENV=\u0026#34;production\u0026#34; # User specific aliases and functions export PATH=\u0026#34;$HOME/.rbenv/bin:$PATH\u0026#34; eval \u0026#34;$(rbenv init -)\u0026#34; export PATH=\u0026#34;$HOME/.rbenv/bin:$PATH\u0026#34; Setting nginx\n[root@new-redmine ~]# cat /etc/nginx/conf.d/redmine.conf upstream redmine { server unix:///opt/redmine/shared/tmp/redmine-puma.sock; } server { listen 80; server_name xxxxxx; root /opt/redmine/current/public; location / { try_files $uri @redmine; } location @redmine { proxy_set_header X-Forwarded-For $remote_addr; proxy_pass \u0026lt;http://redmine\u0026gt;; } } [root@new-redmine ~]# service nginx start Restart server # [root@new-redmine current]# service nginx restart [root@new-redmine current]# service mariadb restart "},{"id":39,"href":"/secret-management/vault/Vault-import-export-secrets/","title":"Vault Import, Export Secrets","section":"Vault","content":" Vault import, export secrets # ./medusa export path --address=\u0026#34;https://vault-url.com\u0026#34; --token=\u0026#34;s.xxx\u0026#34; --format=\u0026#34;yaml\u0026#34; \u0026gt; export.yaml ./medusa import path ./export.yaml --address=\u0026#34;https://https://vault-url.com\u0026#34; --token=\u0026#34;s.xxx\u0026#34; REF: https://github.com/jonasvinther/medusa\n"}]